{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2504e5dd-87b6-4b78-8cf0-b88421399603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Debugging example\n",
    "def divide(a, b):\n",
    "    logging.debug(f\"Dividing {a} by {b}\")\n",
    "    result = a / b\n",
    "    logging.debug(f\"Result: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077272d2-762a-4077-8475-8394d3844dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "divide(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ea505-faa4-40a8-8a9f-f60bbb0d90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_dataframe(sql, token: str): \n",
    "    from google.cloud import bigquery\n",
    "    from google.oauth2 import credentials\n",
    "\n",
    "    CREDENTIALS = google.oauth2.credentials.Credentials(token) # get credentials from token\n",
    "    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n",
    "    df_target = client.query(sql).to_dataframe()\n",
    "\n",
    "    return df_target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b0751-c924-40bc-9cd3-ee81c05ebbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.oauth2.credentials\n",
    "token = !gcloud auth print-access-token\n",
    "token_str = token[0]\n",
    "\n",
    "project_id = 'divg-josh-pr-d1cc3a'\n",
    "dataset_id = 'breast_cancer'\n",
    "table_id = 'breast_cancer_X_val'\n",
    "\n",
    "sql = '''SELECT * FROM `{project_id}.{dataset_id}.{table_id}` '''.format(project_id=project_id,\n",
    "                                                                        dataset_id=dataset_id,\n",
    "                                                                        table_id=table_id,\n",
    "                                                                        )\n",
    "\n",
    "df = sql_to_dataframe(sql=sql, token=token_str)\n",
    "\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d169d0-be67-42ab-981d-f6c82792076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n",
    "    'float_col': [1.1, 2.2, 3.3],\n",
    "    'string_col': ['A', 'B', 'A'],\n",
    "    'category_col': ['cat1', 'cat2', 'cat1'],\n",
    "    'integer_col': [1, 2, 3],\n",
    "    'target': [0, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert date to numerical features\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# Define the preprocessing steps\n",
    "categorical_features = ['string_col', 'category_col']\n",
    "numeric_features = ['float_col', 'integer_col', 'year', 'month', 'day']\n",
    "\n",
    "# One-hot encode categorical features and standardize numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Apply the preprocessor to the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_processed, y)\n",
    "\n",
    "print(\"Original dataset shape:\", X.shape)\n",
    "print(\"Resampled dataset shape:\", X_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabee8a0-356c-4bbb-bfac-3235406de78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
