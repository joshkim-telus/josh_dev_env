{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0c603b-3f78-40d0-bc02-7dac3ea2a76c",
   "metadata": {},
   "source": [
    "### Import Libraries, declare variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf87789-5a0e-488a-a4bf-7969f104635e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "CREATE OR REPLACE TABLE `divg-groovyhoon-pr-d2eab4.nba_product_reco_model.nba_training_dataset` AS \n",
    "\n",
    "SELECT split_type\n",
    ", model_scenario\n",
    ", ref_dt\n",
    ", cust_id\n",
    ", cust_src_id\n",
    ", ban\n",
    ", ban_src_id\n",
    ", lpds_id\n",
    ", fms_address_id\n",
    ", label\n",
    ", label_dt\n",
    ", avg_usg_cnt_4w_news\n",
    ", avg_usg_dl_4w_news\n",
    ", avg_usg_ul_4w_news\n",
    ", avg_usg_cnt_4w_sports\n",
    ", avg_usg_dl_4w_sports\n",
    ", avg_usg_ul_4w_sports\n",
    ", `avg_usg_cnt_4w_tv and movies` AS avg_usg_cnt_4w_tv_and_movies\n",
    ", `avg_usg_dl_4w_tv and movies` AS avg_usg_dl_4w_tv_and_movies\n",
    ", `avg_usg_ul_4w_tv and movies` AS avg_usg_ul_4w_tv_and_movies\n",
    ", bill_wln_zscore_ban_subtotal_amt\n",
    ", CAST(bill_wln_avg_ban_subtotal_amt AS FLOAT64) AS bill_wln_avg_ban_subtotal_amt\n",
    ", bill_wln_zscore_ban_debit_amt\n",
    ", CAST(bill_wln_avg_ban_debit_amt AS FLOAT64) AS bill_wln_avg_ban_debit_amt\n",
    ", bill_wln_zscore_ban_discount_amt\n",
    ", CAST(bill_wln_avg_ban_discount_amt AS FLOAT64) AS bill_wln_avg_ban_discount_amt\n",
    ", bill_wln_zscore_ban_credit_amt\n",
    ", CAST(bill_wln_avg_ban_credit_amt AS FLOAT64) AS bill_wln_avg_ban_credit_amt\n",
    ", CAST(bill_wln_avg_sing_debit_amt AS FLOAT64) AS bill_wln_avg_sing_debit_amt\n",
    ", CAST(bill_wln_avg_sing_discount_amt AS FLOAT64) AS bill_wln_avg_sing_discount_amt\n",
    ", CAST(bill_wln_avg_sing_credit_amt AS FLOAT64) AS bill_wln_avg_sing_credit_amt\n",
    ", CAST(bill_wln_avg_hsic_debit_amt AS FLOAT64) AS bill_wln_avg_hsic_debit_amt\n",
    ", CAST(bill_wln_avg_hsic_discount_amt AS FLOAT64) AS bill_wln_avg_hsic_discount_amt\n",
    ", CAST(bill_wln_avg_hsic_credit_amt AS FLOAT64) AS bill_wln_avg_hsic_credit_amt\n",
    ", CAST(bill_wln_avg_ttv_debit_amt AS FLOAT64) AS bill_wln_avg_ttv_debit_amt\n",
    ", CAST(bill_wln_avg_ttv_discount_amt AS FLOAT64) AS bill_wln_avg_ttv_discount_amt\n",
    ", CAST(bill_wln_avg_ttv_credit_amt AS FLOAT64) AS bill_wln_avg_ttv_credit_amt\n",
    ", CAST(bill_wln_avg_smhm_debit_amt AS FLOAT64) AS bill_wln_avg_smhm_debit_amt\n",
    ", CAST(bill_wln_avg_smhm_discount_amt AS FLOAT64) AS bill_wln_avg_smhm_discount_amt\n",
    ", CAST(bill_wln_avg_smhm_credit_amt AS FLOAT64) AS bill_wln_avg_smhm_credit_amt\n",
    ", CAST(bill_wln_avg_sing_ld_na_call_cnt AS FLOAT64) AS bill_wln_avg_sing_ld_na_call_cnt\n",
    ", CAST(bill_wln_avg_sing_ld_intl_call_cnt AS FLOAT64) AS bill_wln_avg_sing_ld_intl_call_cnt\n",
    ", CAST(bill_wln_avg_hsic_usg_gb AS FLOAT64) AS bill_wln_avg_hsic_usg_gb\n",
    ", CAST(bill_wln_avg_ttv_ppv_cnt AS FLOAT64) AS bill_wln_avg_ttv_ppv_cnt\n",
    ", CAST(bill_wln_avg_ttv_vod_cnt AS FLOAT64) AS bill_wln_avg_ttv_vod_cnt\n",
    ", clk_wls_tot_cnt_r30d\n",
    ", clk_wls_plan_cnt_r30d\n",
    ", clk_wls_device_cnt_r30d\n",
    ", clk_wls_smartwatch_cnt_r30d\n",
    ", clk_wls_tablet_cnt_r30d\n",
    ", clk_wln_tot_cnt_r30d\n",
    ", clk_wln_eligibility_cnt_r30d\n",
    ", clk_wln_sing_cnt_r30d\n",
    ", clk_wln_hsic_cnt_r30d\n",
    ", clk_wln_fibre_cnt_r30d\n",
    ", clk_wln_whsia_cnt_r30d\n",
    ", clk_wln_wifi_plus_cnt_r30d\n",
    ", clk_wln_tv_cnt_r30d\n",
    ", clk_wln_optik_cnt_r30d\n",
    ", clk_wln_pik_cnt_r30d\n",
    ", clk_wln_streamplus_cnt_r30d\n",
    ", clk_wln_streaming_cnt_r30d\n",
    ", clk_wln_security_cnt_r30d\n",
    ", clk_wln_smarthome_security_cnt_r30d\n",
    ", clk_wln_online_security_cnt_r30d\n",
    ", clk_wln_smartwear_security_cnt_r30d\n",
    ", clk_deal_tot_cnt_r30d\n",
    ", clk_deal_wls_cnt_r30d\n",
    ", clk_deal_wln_cnt_r30d\n",
    ", clk_deal_wln_sing_cnt_r30d\n",
    ", clk_deal_wln_hsic_cnt_r30d\n",
    ", clk_deal_wln_whsia_cnt_r30d\n",
    ", clk_deal_wln_tv_cnt_r30d\n",
    ", clk_deal_wln_security_cnt_r30d\n",
    ", clk_upgr_tot_cnt_r30d\n",
    ", clk_upgr_wls_cnt_r30d\n",
    ", clk_upgr_wln_cnt_r30d\n",
    ", clk_upgr_wln_sing_cnt_r30d\n",
    ", clk_upgr_wln_hsic_cnt_r30d\n",
    ", clk_upgr_wln_whsia_cnt_r30d\n",
    ", clk_upgr_wln_tv_cnt_r30d\n",
    ", clk_upgr_wln_security_cnt_r30d\n",
    ", clk_chg_tot_cnt_r30d\n",
    ", clk_chg_wls_cnt_r30d\n",
    ", clk_chg_wln_cnt_r30d\n",
    ", clk_chg_wln_sing_cnt_r30d\n",
    ", clk_chg_wln_hsic_cnt_r30d\n",
    ", clk_chg_wln_whsia_cnt_r30d\n",
    ", clk_chg_wln_tv_cnt_r30d\n",
    ", clk_chg_wln_security_cnt_r30d\n",
    ", clk_health_livingwell_cnt_r30d\n",
    ", clk_health_mypet_cnt_r30d\n",
    ", clk_travel_cnt_r30d\n",
    ", clk_billing_cnt_r30d\n",
    ", clk_service_agreement_cnt_r30d\n",
    ", acct_cr_risk_txt\n",
    ", acct_ebill_ind\n",
    ", cust_cr_val_txt\n",
    ", cust_pref_lang_txt\n",
    ", cust_prov_state_cd\n",
    ", cust_age_yr_num\n",
    ", demogr_med_age\n",
    ", demogr_avg_child\n",
    ", demogr_pct_family_with_child_living_at_home\n",
    ", demogr_employment_rate\n",
    ", demogr_avg_household_size\n",
    ", demogr_avg_income\n",
    ", demogr_med_income\n",
    ", demogr_urban_flag\n",
    ", demogr_rural_flag\n",
    ", demogr_family_flag\n",
    ", demogr_lsname_large_diverse_families\n",
    ", demogr_lsname_younger_singles_and_couples\n",
    ", demogr_lsname_very_young_singles_and_couples\n",
    ", demogr_lsname_older_families_and_empty_nests\n",
    ", demogr_lsname_middle_age_families\n",
    ", demogr_lsname_mature_singles_and_couples\n",
    ", demogr_lsname_young_families\n",
    ", demogr_lsname_school_age_families\n",
    ", demogr_retired_pstl_cd_ind\n",
    ", demogr_census_division_typ\n",
    ", demogr_lifestage_sort\n",
    ", CAST(hs_usg_avg_tot_gb AS FLOAT64) AS hs_usg_avg_tot_gb\n",
    ", CAST(hs_usg_avg_dl_gb AS FLOAT64) AS hs_usg_avg_dl_gb\n",
    ", CAST(hs_usg_avg_ul_gb AS FLOAT64) AS hs_usg_avg_ul_gb\n",
    ", prod_latest_actvn_dt\n",
    ", prod_latest_deactvn_dt\n",
    ", prod_tot_cnt\n",
    ", prod_wln_cnt\n",
    ", prod_wls_cnt\n",
    ", prod_mob_cnt\n",
    ", prod_sing_cnt\n",
    ", prod_hsic_cnt\n",
    ", prod_whsia_cnt\n",
    ", prod_ttv_cnt\n",
    ", prod_smhm_cnt\n",
    ", prod_tos_cnt\n",
    ", prod_wifiplus_cnt\n",
    ", prod_stv_cnt\n",
    ", prod_other_cnt\n",
    ", prod_deact_prod_cnt\n",
    ", prod_act_prod_cnt_r7d\n",
    ", prod_act_wln_cnt_r7d\n",
    ", prod_deact_prod_cnt_r7d\n",
    ", prod_deact_wln_cnt_r7d\n",
    ", hsic_tenure_days\n",
    ", contract_end_date_hsic\n",
    ", sing_tenure_days\n",
    ", contract_end_date_sing\n",
    ", ttv_tenure_days\n",
    ", contract_end_date_ttv\n",
    ", smhm_tenure_days\n",
    ", contract_end_date_smhm\n",
    ", ffh_tenure\n",
    ", new_account_ind\n",
    "\n",
    "FROM `divg-groovyhoon-pr-d2eab4.nba_product_reco_model.nba_training_dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1294f3f-ee1c-4c57-bbb1-635ef08b52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import google\n",
    "from google.oauth2 import credentials\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# build model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SERVICE_TYPE = 'nba_product_reco_model'\n",
    "DATASET_ID = 'nba_product_reco_model'\n",
    "PROJECT_ID = 'divg-groovyhoon-pr-d2eab4' #mapping['PROJECT_ID']\n",
    "RESOURCE_BUCKET = 'divg-groovyhoon-pr-d2eab4-default' #mapping['resources_bucket']\n",
    "FILE_BUCKET = 'divg-groovyhoon-pr-d2eab4-default' #mapping['gcs_csv_bucket']\n",
    "REGION = 'northamerica-northeast1' #mapping['REGION']\n",
    "MODEL_ID = '9999'\n",
    "FOLDER_NAME = 'nba_product_reco_model'.format(MODEL_ID)\n",
    "QUERIES_PATH = 'vertex_pipelines/' + FOLDER_NAME + '/queries/'\n",
    "TRAIN_TABLE_ID = 'nba_training_dataset_v3'\n",
    "VAL_TABLE_ID = 'nba_test_dataset_v3'\n",
    "SCORE_TABLE_ID = 'bq_product_reco_scores'\n",
    "\n",
    "# scoringDate = date(2023, 10, 13)  # date.today() - relativedelta(days=2)- relativedelta(months=30)\n",
    "# valScoringDate = date(2023, 11, 13)  # scoringDate - relativedelta(days=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30300f-ff71-417d-956f-6d3dcede6c29",
   "metadata": {},
   "source": [
    "### import bq to dataframe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e098413-7211-4346-b1c9-eafd38ef076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import credentials\n",
    "\n",
    "def import_bq_to_dataframe(project_id, dataset_id, table_id, client): \n",
    "    \n",
    "    \"\"\"\n",
    "    Imports a specific table from BigQuery to a DataFrame. \n",
    "    \n",
    "    Args: \n",
    "        project_id: The name of the project_id where the table is located.\n",
    "        dataset_id: The name of the dataset_id where the table is located.\n",
    "        table_id: The name of the table_id you wish to import to DataFrame.\n",
    "        client: A BigQuery client instance. e.g. client = bigquery.Client(project=project_id).\n",
    "\n",
    "    Returns: \n",
    "        A DataFrame\n",
    "        \n",
    "    Example: \n",
    "        import_bq_to_dataframe('bi-stg-divg-speech-pr-9d940b', 'call_to_retention_dataset', 'bq_ctr_pipeline_dataset')\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    sql = f\"SELECT * FROM `{project_id}.{dataset_id}.{table_id}`\"\n",
    "    \n",
    "    df_return = client.query(sql).to_dataframe()\n",
    "\n",
    "    return df_return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a31e45-47f9-445e-aab4-1e2d8243e1f9",
   "metadata": {},
   "source": [
    "### define get_lift function, import df_train and df_test from gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3837b0-0180-4a8a-978d-b56402062efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_id = PROJECT_ID\n",
    "region = REGION\n",
    "resource_bucket = RESOURCE_BUCKET\n",
    "file_bucket = FILE_BUCKET\n",
    "service_type=SERVICE_TYPE\n",
    "project_id=PROJECT_ID\n",
    "dataset_id=DATASET_ID\n",
    "train_table_id = TRAIN_TABLE_ID\n",
    "val_table_id = VAL_TABLE_ID\n",
    "\n",
    "def get_lift(prob, y_test, q):\n",
    "    result = pd.DataFrame(columns=['Prob', 'Churn'])\n",
    "    result['Prob'] = prob\n",
    "    result['Churn'] = y_test\n",
    "    # result['Decile'] = pd.qcut(1-result['Prob'], 10, labels = False)\n",
    "    result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n",
    "    add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n",
    "    add.columns = ['Decile', 'avg_real_churn_rate']\n",
    "    result = result.merge(add, on='Decile', how='left')\n",
    "    result.sort_values('Decile', ascending=True, inplace=True)\n",
    "    lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n",
    "    lg.columns = ['Decile', 'avg_model_pred_churn_rate']\n",
    "    lg.sort_values('Decile', ascending=False, inplace=True)\n",
    "    lg['avg_churn_rate_total'] = result['Churn'].mean()\n",
    "    lg = lg.merge(add, on='Decile', how='left')\n",
    "    lg['lift'] = lg['avg_real_churn_rate'] / lg['avg_churn_rate_total']\n",
    "\n",
    "    return lg\n",
    "\n",
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "df_train = import_bq_to_dataframe(project_id, dataset_id, train_table_id, client) #-- Jan to Oct \n",
    "df_val = import_bq_to_dataframe(project_id, dataset_id, val_table_id, client) #-- Nov and Dec\n",
    "\n",
    "scenario_to_target = {\n",
    "    'hsic_acquisition': 0,\n",
    "    'ttv_acquisition': 1,\n",
    "    'sing_acquisition': 2,\n",
    "    'shs_acquisition': 3, \n",
    "    'tos_acquisition': 4, \n",
    "    'wifi_acquisition': 5, \n",
    "    'lwc_acquisition': 6, \n",
    "    'sws_acquisition': 7, \n",
    "    'hpro_acquisition': 8\n",
    "}\n",
    "\n",
    "df_train['target'] = df_train['model_scenario'].map(scenario_to_target)\n",
    "df_val['target'] = df_val['model_scenario'].map(scenario_to_target)\n",
    "\n",
    "print(f'df_train: {df_train.shape}')\n",
    "print(f'df_val: {df_val.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94961cc0-7e92-44eb-9e1e-15d16d2024ed",
   "metadata": {},
   "source": [
    "### add targets to df_train and df_target \n",
    "\n",
    "- df_target_train is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q3` \n",
    "- df_target_test is from `divg-josh-pr-d1cc3a.tos_crosssell.bq_tos_cross_sell_targets_q4` \n",
    "- some parts of the code and sql queries need to be dynamically adjusted to be included in the deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc272d97-768b-401b-9100-923cc63cf1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "# df train - Jan to Aug \n",
    "# df train - Sep to Oct \n",
    "df_train, df_test = train_test_split(df_train, test_size=0.3, random_state=42, stratify=df_train['target'])\n",
    "\n",
    "df_train.to_csv('gs://{}/{}/{}_train_final.csv'.format(FILE_BUCKET, SERVICE_TYPE, SERVICE_TYPE), index=False)\n",
    "df_test.to_csv('gs://{}/{}/{}_test_final.csv'.format(FILE_BUCKET, SERVICE_TYPE, SERVICE_TYPE), index=False)\n",
    "df_val.to_csv('gs://{}/{}/{}_val_final.csv'.format(FILE_BUCKET, SERVICE_TYPE, SERVICE_TYPE), index=False)\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = df_train.columns.values\n",
    "cols_2 = df_test.columns.values\n",
    "cols_3 = df_val.columns.values\n",
    "\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "cols = set(cols).intersection(set(cols_3))\n",
    "\n",
    "features_to_exclude = ['split_type','model_scenario','ref_dt','cust_id','cust_src_id','ban','ban_src_id','lpds_id',\n",
    "                       'fms_address_id','label','label_dt', 'prod_latest_actvn_dt', 'prod_latest_deactvn_dt', 'target', \n",
    "                       'contract_end_date_hsic', 'contract_end_date_hsic', 'contract_end_date_sing', 'contract_end_date_ttv', 'contract_end_date_smhm'] \n",
    "\n",
    "features = [f for f in cols if f not in features_to_exclude]\n",
    "\n",
    "ban_train = df_train[['ban', 'lpds_id']]\n",
    "X_train = df_train[features]\n",
    "y_train = np.squeeze(df_train['target'].values)\n",
    "target_train = df_train['target']\n",
    "\n",
    "ban_test = df_test[['ban', 'lpds_id']]\n",
    "X_test = df_test[features]\n",
    "y_test = np.squeeze(df_test['target'].values)\n",
    "target_test = df_test['target']\n",
    "\n",
    "ban_val = df_val[['ban', 'lpds_id']]\n",
    "X_val = df_val[features]\n",
    "y_val = np.squeeze(df_val['target'].values)\n",
    "target_val = df_val['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee477829-f647-4302-b142-67f33d33dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591fa94-0f6d-47a7-9bb5-53d4a39ca42b",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38820930-8f64-4d21-bd82-54aef8e6d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(df, cat_feature_names): \n",
    "    \n",
    "    df_income_dummies = pd.get_dummies(df[cat_feature_names]) \n",
    "    df_income_dummies.columns = df_income_dummies.columns.str.replace('&', 'and')\n",
    "    df_income_dummies.columns = df_income_dummies.columns.str.replace(' ', '_')\n",
    "\n",
    "    df.drop(columns=cat_feature_names, axis=1, inplace=True)\n",
    "\n",
    "    df = df.join(df_income_dummies)\n",
    "    \n",
    "    #column name clean-up\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    df.columns = df.columns.str.replace('-', '_')\n",
    "    \n",
    "    return df\n",
    "\n",
    "cat_feature_names = ['acct_cr_risk_txt', 'acct_ebill_ind', 'cust_cr_val_txt', 'cust_pref_lang_txt', 'cust_prov_state_cd', 'demogr_census_division_typ']\n",
    "\n",
    "# cat_feature_names = ['revenue_band', 'payment_mthd', 'ebill_ind', 'dvc_non_telus_ind', 'credit_class', 'contract_type', 'bacct_delinq_ind', 'urbn_rur_ind',\n",
    "#                      'dnc_sms_ind', 'dnc_em_ind', 'data_usg_trend', 'wls_data_plan_ind', 'wls_data_shr_plan_ind']\n",
    "    \n",
    "X_train = to_categorical(X_train, cat_feature_names)\n",
    "X_test = to_categorical(X_test, cat_feature_names)\n",
    "X_val = to_categorical(X_val, cat_feature_names)\n",
    "\n",
    "#set up features (list)\n",
    "cols_1 = X_train.columns.values\n",
    "cols_2 = X_test.columns.values\n",
    "cols_3 = X_val.columns.values\n",
    "\n",
    "cols = set(cols_1).intersection(set(cols_2))\n",
    "cols = set(cols).intersection(set(cols_3))\n",
    "\n",
    "features = [f for f in cols if f not in features_to_exclude]\n",
    "\n",
    "# features = ['contract_type_MTM'\n",
    "# , 'contract_type_BYOD'\n",
    "# , 'contract_type_On_Contract'\n",
    "# , 'cntrct_end_recency'\n",
    "# , 'cntrct_start_recency'\n",
    "# , 'ban_tenure'\n",
    "# , 'contract_mth'\n",
    "# , 'urbn_rur_ind_Rural'\n",
    "# , 'sub_tenure'\n",
    "# , 'urbn_rur_ind_Urban'\n",
    "# , 'dvc_non_telus_ind_Y'\n",
    "# , 'demo_lsname_Large_Diverse_Families'\n",
    "# , 'dvc_non_telus_ind_N'\n",
    "# , 'demo_sgname_Diverse_Urban_Fringe'\n",
    "# , 'demo_sgname_Lower_Middle_Rural'\n",
    "# , 'data_usg_trend_unknown'\n",
    "# , 'demo_sgname_Midscale_Urban_Fringe'\n",
    "# , 'clk_app_offer'\n",
    "# , 'bacct_delinq_ind_Y'\n",
    "# , 'revenue_band_D'\n",
    "# , 'payment_mthd_R'\n",
    "# , 'clk_app_usage'\n",
    "# , 'demo_sgname_Upper_Middle_Suburbia'\n",
    "# , 'demo_sgname_Urban_Diversity'\n",
    "# , 'easy_pymt_avg'\n",
    "# , 'rate_plan_amt'\n",
    "# , 'demo_sgname_Upscale_Suburban_Diversity'\n",
    "# , 'sub_cnt'\n",
    "# , 'clk_app_ovrview'\n",
    "# , 'credit_class_D'\n",
    "# , 'demo_sgname_Town_Mix'\n",
    "# , 'demo_sgname_Young_Urban_Core'\n",
    "# , 'payment_mthd_C'\n",
    "# , 'bacct_delinq_ind_N'\n",
    "# , 'artm_min_qty_avg'\n",
    "# , 'credit_class_V'\n",
    "# , 'hm_call_cnt_avg'\n",
    "# , 'wls_data_shr_plan_ind_Y'\n",
    "# , 'demo_lsname_Older_Families_and_Empty_Nests'\n",
    "# , 'dnc_sms_ind_N'\n",
    "# , 'demo_lsname_School_Age_Families'\n",
    "# , 'credit_class_X'\n",
    "# , 'clk_web_plan'\n",
    "# , 'hm_data_usg_avg'\n",
    "# , 'revenue_band_F'\n",
    "# , 'demo_lsname_Young_Families'\n",
    "# , 'demo_lsname_Middle_Age_Families'\n",
    "# , 'clk_app_subslct'\n",
    "# , 'cr_disc_amt_avg'\n",
    "# , 'tot_data_usg_avg'\n",
    "# , 'age'\n",
    "# , 'demo_avg_income'\n",
    "# , 'data_usg_trend_increasing'\n",
    "# , 'revenue_band_N'\n",
    "# , 'revenue_band_C'\n",
    "# , 'dvc_non_telus_ind_U'\n",
    "# , 'wls_data_plan_ind_N'\n",
    "# , 'ebill_ind_N'\n",
    "# , 'net_inv_amt_avg'\n",
    "# , 'clk_app_bill'\n",
    "# , 'clk_app_changefg'\n",
    "# , 'revenue_band_NA'\n",
    "# , 'demo_sgname_Older_Urban_Francophone'\n",
    "# , 'demo_sgname_Upper_Middle_Rural'\n",
    "# , 'sms_dnc_recency'\n",
    "# , 'demo_sgname_Upper_Middle_Suburban_Francophone'\n",
    "# , 'demo_sgname_Unassigned'\n",
    "# , 'clk_web_bill'\n",
    "# , 'clk_app_drawer'\n",
    "# , 'demo_sgname_Rural_Francophone'\n",
    "# , 'clk_web_phnumber'\n",
    "# , 'ld_min_qty_avg'\n",
    "# , 'em_dnc_recency'\n",
    "# , 'effort_durtn_sec_qty_s'\n",
    "# ]\n",
    "\n",
    "X_train = X_train[features] \n",
    "X_test = X_test[features] \n",
    "X_val = X_val[features]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb3c25-0efe-4842-9dd2-53da180d7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# del df_train, df_val, df_test\n",
    "del df_train, df_test, df_val\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd29e3-d1b3-4cbe-983c-b0033ed8554a",
   "metadata": {},
   "source": [
    "### fit training data in xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7616d7-5909-4cb8-8e74-821d3e92dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build model and fit in training data\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=250,\n",
    "    max_depth=7,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softproba',\n",
    "    num_class=3, \n",
    "    eval_metric='mlogloss', \n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    ")\n",
    "\n",
    "# xgb_model = xgb.XGBClassifier(\n",
    "#     learning_rate=0.1,\n",
    "#     n_estimators=1000,\n",
    "#     max_depth=5,\n",
    "#     min_child_weight=1,\n",
    "#     gamma=0,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     objective='multi:softproba',\n",
    "#     num_class=3, \n",
    "#     eval_metric='mlogloss', \n",
    "#     nthread=4,\n",
    "#     scale_pos_weight=1,\n",
    "#     seed=27\n",
    "# )\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('xgb training done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abc939-f3aa-408a-b3a6-0beb1ff89c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca769f9-add0-4dc1-b9ee-b773e64f1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafd6fe-c34b-451b-8d42-c8d4e80e9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = y_pred[:, 0]\n",
    "y_pred_1 = y_pred[:, 1]\n",
    "y_pred_2 = y_pred[:, 2]\n",
    "y_pred_3 = y_pred[:, 3]\n",
    "y_pred_4 = y_pred[:, 4]\n",
    "y_pred_5 = y_pred[:, 5]\n",
    "y_pred_6 = y_pred[:, 6]\n",
    "y_pred_7 = y_pred[:, 7]\n",
    "y_pred_8 = y_pred[:, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42baa80-bee6-4aa7-80e3-2c341142c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predictions on X_test\n",
    "# y_pred = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "\n",
    "df_ban_test = ban_test\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba_0'] = y_pred_0\n",
    "df_test_exp['y_pred_proba_1'] = y_pred_1\n",
    "df_test_exp['y_pred_proba_2'] = y_pred_2\n",
    "df_test_exp['y_pred_proba_3'] = y_pred_3\n",
    "df_test_exp['y_pred_proba_4'] = y_pred_4\n",
    "df_test_exp['y_pred_proba_5'] = y_pred_5\n",
    "df_test_exp['y_pred_proba_6'] = y_pred_6\n",
    "df_test_exp['y_pred_proba_7'] = y_pred_7\n",
    "df_test_exp['y_pred_proba_8'] = y_pred_8\n",
    "\n",
    "\n",
    "# df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194cad1-eba7-46ad-8052-692b08f32107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_exp.to_csv(\"gs://divg-groovyhoon-pr-d2eab4-default/downloads/df_test_exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217c02c-846f-4bec-9b92-0819257a812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bd83a-57e9-4891-9512-4e9349570493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81897c94-69be-4066-9613-8509dcaaafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = y_pred[:, 0]\n",
    "y_pred_1 = y_pred[:, 1]\n",
    "y_pred_2 = y_pred[:, 2]\n",
    "y_pred_3 = y_pred[:, 3]\n",
    "y_pred_4 = y_pred[:, 4]\n",
    "y_pred_5 = y_pred[:, 5]\n",
    "y_pred_6 = y_pred[:, 6]\n",
    "y_pred_7 = y_pred[:, 7]\n",
    "y_pred_8 = y_pred[:, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291408bb-7da9-4100-a8f4-a6cc5bea02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predictions on X_val\n",
    "# y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "\n",
    "df_ban_val = ban_val\n",
    "df_val_exp = df_ban_val.join(X_val) \n",
    "df_val_exp['y_val'] = y_val\n",
    "df_val_exp['y_pred_proba_0'] = y_pred_0\n",
    "df_val_exp['y_pred_proba_1'] = y_pred_1\n",
    "df_val_exp['y_pred_proba_2'] = y_pred_2\n",
    "df_val_exp['y_pred_proba_3'] = y_pred_3\n",
    "df_val_exp['y_pred_proba_4'] = y_pred_4\n",
    "df_val_exp['y_pred_proba_5'] = y_pred_5\n",
    "df_val_exp['y_pred_proba_6'] = y_pred_6\n",
    "df_val_exp['y_pred_proba_7'] = y_pred_7\n",
    "df_val_exp['y_pred_proba_8'] = y_pred_8\n",
    "\n",
    "# df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79a59f-8a7c-42b9-81d2-06e4854ea513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_exp.to_csv(\"gs://divg-groovyhoon-pr-d2eab4-default/downloads/df_val_exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0bb1d3-4362-47c1-ac15-94c0b9299d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716cb25e-044f-4479-a78f-f825702ba5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=3)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [30, 50, 100, 200, 500, 1000],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'eval_metric': ['mlogloss']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdabeac-b4ad-44d8-8dcf-9cd2dbc31c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.best_model(X_val)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ab70b-10a5-402e-b9f6-4d857dcbe927",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = y_pred[:, 0]\n",
    "y_pred_1 = y_pred[:, 1]\n",
    "y_pred_2 = y_pred[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd0f27-b35d-415e-8f4c-3a0483e0b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predictions on X_val\n",
    "# y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "\n",
    "df_ban_val = ban_val\n",
    "df_val_exp = df_ban_val.join(X_val) \n",
    "df_val_exp['y_val'] = y_val\n",
    "df_val_exp['y_pred_proba_0'] = y_pred_0\n",
    "df_val_exp['y_pred_proba_1'] = y_pred_1\n",
    "df_val_exp['y_pred_proba_2'] = y_pred_2\n",
    "\n",
    "# df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cb419-d530-4d37-83a1-19343b27cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_exp.to_csv(\"gs://divg-groovyhoon-pr-d2eab4-default/downloads/df_val_exp_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ea7ec-74db-4419-84bb-0d44545fec56",
   "metadata": {},
   "source": [
    "### make predictions on X_test set, assign deciles to the predicted values, and save in df_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c55fb-754b-4fa9-b0ac-cdcf45a3dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions on X_test\n",
    "y_pred = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "\n",
    "#join ban_test, X_test, y_test and y_pred and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_test = ban_test\n",
    "df_test_exp = df_ban_test.join(X_test) \n",
    "df_test_exp['y_test'] = y_test\n",
    "df_test_exp['y_pred_proba'] = y_pred\n",
    "df_test_exp['y_pred'] = (df_test_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_test_exp['decile'] = pd.qcut(df_test_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(y_pred, y_test, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767b8f5-8bdb-4d5f-9b5b-2b340289cb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### export df_test_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2015d1-d1a5-410f-95c5-2b5054e2abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_exp.to_csv('gs://{}/{}/{}_df_test_exp.csv'.format(file_bucket, SERVICE_TYPE, SERVICE_TYPE, index=True))\n",
    "print(\"....df_test_exp exported\")\n",
    "\n",
    "lg.to_csv('gs://{}/{}/{}_lift_on_test_data.csv'.format(file_bucket, SERVICE_TYPE, SERVICE_TYPE, index=False))\n",
    "print(\"....lift_to_csv done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a67377-2467-47f9-aa71-2063716eda1f",
   "metadata": {},
   "source": [
    "### make predictions on X_val set, assign deciles to the predicted values, and save in df_val_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7231aba-49a5-4a16-9c57-2061ebe27892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions on X_val\n",
    "y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "\n",
    "#join ban_val, X_val, y_val and y_pred and print to csv\n",
    "#CHECK THE SIZE OF EACH COMPONENT BEFORE JOINING\n",
    "q=10\n",
    "df_ban_val = ban_val\n",
    "df_val_exp = df_ban_val.join(X_val) \n",
    "df_val_exp['y_val'] = y_val\n",
    "df_val_exp['y_pred_proba'] = y_pred\n",
    "df_val_exp['y_pred'] = (df_val_exp['y_pred_proba'] > 0.5).astype(int)\n",
    "df_val_exp['decile'] = pd.qcut(df_val_exp['y_pred_proba'], q, labels=[i for i in range(q, 0, -1)])\n",
    "\n",
    "lg = get_lift(y_pred, y_val, q)\n",
    "\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca9c17-8af8-4f29-b3a1-d35a1c50cf19",
   "metadata": {},
   "source": [
    "### export df_val_exp and lift scores to gcs bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c3887-fc3a-44a7-b037-4bdfd61eb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_exp.to_csv('gs://{}/{}/{}_df_val_exp.csv'.format(file_bucket, SERVICE_TYPE, SERVICE_TYPE, index=True))\n",
    "print(\"....df_val_exp exported\")\n",
    "\n",
    "lg.to_csv('gs://{}/{}/{}_lift_on_val_data.csv'.format(file_bucket, SERVICE_TYPE, SERVICE_TYPE, index=False))\n",
    "print(\"....lift_to_csv done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864bda6-bda0-4032-9704-f513da84e132",
   "metadata": {},
   "source": [
    "### get feature importances from xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43768ef0-d6cc-40e4-a3a9-dbcdbceedb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from xgboost model\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Get the index of importances from greatest importance to least\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "x = range(len(importances))\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create tick labels \n",
    "labels = np.array(feature_names)[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb976c57-68c2-4d13-84c6-7f138ae560bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in sorted_index: \n",
    "    print(f'{feature_names[idx]}, {importances[idx]}', end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9b69c-0ab4-4595-b2f2-3b0a6387d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edf5cf-4f19-41c3-ab79-3b560cdd1f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9209e72-72ba-4c08-a7c6-c8317836fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8515b-07cd-4c76-9d79-944145ef3de1",
   "metadata": {},
   "source": [
    "### Load results to BQ - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b9b52-17c6-4c7f-8a36-9afdfc17f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_TABLE_ID = 'bq_telus_12_months_churn_scores'\n",
    "\n",
    "project_id = PROJECT_ID \n",
    "dataset_id = DATASET_ID\n",
    "score_table_id = SCORE_TABLE_ID\n",
    "\n",
    "# get full score to cave into bucket\n",
    "pred_prob = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n",
    "result = pd.DataFrame(columns=['ban', 'subscriber_no', 'score_date', 'y_true', 'y_pred'])\n",
    "\n",
    "result['ban'] = list(ban_val['ban'])\n",
    "result['ban'] = result['ban'].astype('str')\n",
    "\n",
    "result['subscriber_no'] = list(ban_val['ban'])\n",
    "result['subscriber_no'] = result['subscriber_no'].astype('str')\n",
    "\n",
    "result['score_date'] = \"2023-11-04\"\n",
    "\n",
    "result['y_true'] = list(y_val)\n",
    "result['y_true'] = result['y_true'].fillna(0.0).astype('float64')\n",
    "\n",
    "result['y_pred'] = list(pred_prob)\n",
    "result['y_pred'] = result['y_pred'].fillna(0.0).astype('float64')\n",
    "\n",
    "############# updated up to here ############\n",
    "\n",
    "result.to_csv('gs://{}/{}/ucar/{}_prediction_v2.csv'.format(file_bucket, service_type, service_type), index=False)\n",
    "\n",
    "# define dtype_bq_mapping\n",
    "dtype_bq_mapping = {np.dtype('int64'): 'INTEGER', \n",
    "np.dtype('float64'):  'FLOAT', \n",
    "np.dtype('float32'):  'FLOAT', \n",
    "np.dtype('object'):  'STRING', \n",
    "np.dtype('bool'):  'BOOLEAN', \n",
    "np.dtype('datetime64[ns]'):  'DATE', \n",
    "pd.Int64Dtype(): 'INTEGER'} \n",
    "\n",
    "# export df_final to bigquery \n",
    "schema_list = [] \n",
    "for column in result.columns: \n",
    "    schema_list.append(bigquery.SchemaField(column, dtype_bq_mapping[result.dtypes[column]], mode='NULLABLE')) \n",
    "print(schema_list) \n",
    "\n",
    "dest_table = f'{project_id}.{dataset_id}.{score_table_id}'\n",
    "\n",
    "# Sending to bigquery \n",
    "client = get_gcp_bqclient(project_id)\n",
    "job_config = bigquery.LoadJobConfig(schema=schema_list, write_disposition='WRITE_TRUNCATE') \n",
    "job = client.load_table_from_dataframe(result, dest_table, job_config=job_config) \n",
    "job.result() \n",
    "\n",
    "table = client.get_table(dest_table) # Make an API request \n",
    "print(\"Loaded {} rows and {} columns to {}\".format(table.num_rows, len(table.schema), table_id)) \n",
    "\n",
    "time.sleep(60)\n",
    "\n",
    "# table_ref = f'{project_id}.{dataset_id}.{score_table}'\n",
    "# client = bigquery.Client(project=project_id)\n",
    "# table = client.get_table(table_ref)\n",
    "# schema = table.schema\n",
    "\n",
    "# ll = []\n",
    "# for item in schema:\n",
    "#     col = item.name\n",
    "#     d_type = item.field_type\n",
    "#     if 'float' in str(d_type).lower():\n",
    "#         d_type = 'FLOAT64'\n",
    "#     ll.append((col, d_type))\n",
    "\n",
    "#     if 'integer' in str(d_type).lower():\n",
    "#         result[col] = result[col].fillna(0).astype(int)\n",
    "#     if 'float' in str(d_type).lower():\n",
    "#         result[col] = result[col].fillna(0.0).astype(float)\n",
    "#     if 'string' in str(d_type).lower():\n",
    "#         result[col] = result[col].fillna('').astype(str)\n",
    "\n",
    "# table_ref = '{}.{}.{}'.format(project_id, dataset_id, temp_table)\n",
    "# client = bigquery.Client(project=project_id)\n",
    "# if if_tbl_exists(client, table_ref):\n",
    "#     client.delete_table(table_ref)\n",
    "\n",
    "# client.create_table(table_ref)\n",
    "# config = bigquery.LoadJobConfig(schema=schema)\n",
    "# config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "# bq_table_instance = client.load_table_from_dataframe(result, table_ref, job_config=config)\n",
    "# time.sleep(5)\n",
    "\n",
    "# drop_sql = f\"\"\"delete from `{project_id}.{dataset_id}.{score_table}` where score_date = '{score_date_dash}'\"\"\"  # .format(project_id, dataset_id, score_date_dash)\n",
    "# client.query(drop_sql)\n",
    "# #\n",
    "# load_sql = f\"\"\"insert into `{project_id}.{dataset_id}.{score_table}`\n",
    "#               select * from `{project_id}.{dataset_id}.{temp_table}`\"\"\"\n",
    "# client.query(load_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf0cd1-afbc-42e6-9a2f-fd8b727c2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20d37b-0e62-4c81-b446-a88539baf2d9",
   "metadata": {},
   "source": [
    "### save the model in gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e0caa-94a8-497c-a395-15a1ac041f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model in GCS\n",
    "from datetime import datetime\n",
    "models_dict = {}\n",
    "create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "models_dict['create_time'] = create_time\n",
    "models_dict['model'] = xgb_model\n",
    "models_dict['features'] = features\n",
    "\n",
    "with open('model_dict.pkl', 'wb') as handle:\n",
    "    pickle.dump(models_dict, handle)\n",
    "handle.close()\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(file_bucket)\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "blob = bucket.blob(MODEL_PATH)\n",
    "if not blob.exists(storage_client):\n",
    "    blob.upload_from_string('')\n",
    "\n",
    "model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n",
    "blob = bucket.blob(model_name_onbkt)\n",
    "blob.upload_from_filename('model_dict.pkl')\n",
    "\n",
    "print(f\"....model loaded to GCS done at {str(create_time)}\")\n",
    "\n",
    "time.sleep(300)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c02b2b6-b059-4dde-9393-ad457eebf60e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d9d01-f009-45c6-90fe-95a61cc169cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb40188a-3865-4993-be01-fb27f7d07dd6",
   "metadata": {},
   "source": [
    "### load the latest saved xgb_model to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f240186-29e9-4d12-8c11-bb468cae8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "# df_score = pd.read_csv('gs://{}/{}_score.csv.gz'.format(file_bucket, service_type), compression='gzip')\n",
    "# df_score.dropna(subset=['ban'], inplace=True)\n",
    "# df_score.reset_index(drop=True, inplace=True)\n",
    "# print('......scoring data loaded:{}'.format(df_score.shape))\n",
    "# time.sleep(10)\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "MODEL_PATH = '{}_xgb_models/'.format(service_type)\n",
    "\n",
    "def load_model(file_bucket: str, service_type: str): \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(file_bucket)\n",
    "    blobs = storage_client.list_blobs(file_bucket, prefix='{}{}_models_xgb_'.format(MODEL_PATH, service_type))\n",
    "\n",
    "    model_lists = []\n",
    "    for blob in blobs:\n",
    "        model_lists.append(blob.name)\n",
    "\n",
    "    blob = bucket.blob(model_lists[-1])\n",
    "    blob_in = blob.download_as_string()\n",
    "    model_dict = pickle.loads(blob_in)\n",
    "    xgb_model = model_dict['model']\n",
    "    features = model_dict['features']\n",
    "    print('...... model loaded')\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return xgb_model, features\n",
    "\n",
    "xgb_model, features = load_model(file_bucket = FILE_BUCKET, service_type = SERVICE_TYPE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bbaf0-6a67-4151-8504-a187037aa4f8",
   "metadata": {},
   "source": [
    "### backup codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced94be-d4ec-4eb5-8aed-8199f09bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "\n",
    "#instantiate df_target_train and df_target_test\n",
    "sql_train = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q3` '''.format(project_id, dataset_id)\n",
    "df_target_train = client.query(sql_train).to_dataframe()\n",
    "df_target_train = df_target_train.loc[\n",
    "    df_target_train['YEAR_MONTH'] == \"2022-Q3\"] #'-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_train['ban'] = df_target_train['ban'].astype('int64')\n",
    "df_target_train = df_target_train.groupby('ban').tail(1)\n",
    "\n",
    "df_train = df_train.merge(df_target_train[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_train.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_train.dropna(subset=['target'], inplace=True)\n",
    "df_train['target'] = df_train['target'].astype(int)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32473d2-a75d-48ff-afc1-f34af20e2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9b389-df11-402a-ab09-20bd55af3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcp_bqclient(project_id, use_local_credential=True):\n",
    "    token = os.popen('gcloud auth print-access-token').read()\n",
    "    token = re.sub(f'\\n$', '', token)\n",
    "    credentials = google.oauth2.credentials.Credentials(token)\n",
    "\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    if use_local_credential:\n",
    "        bq_client = bigquery.Client(project=project_id, credentials=credentials)\n",
    "    return bq_client\n",
    "\n",
    "client = get_gcp_bqclient(project_id)\n",
    "sql_test = ''' SELECT * FROM `{}.{}.bq_tos_cross_sell_targets_q4` '''.format(project_id, dataset_id)\n",
    "df_target_test = client.query(sql_test).to_dataframe()\n",
    "df_target_test = df_target_test.loc[\n",
    "    df_target_test['YEAR_MONTH'] == \"2022-Q4\"] #'-'.join(score_date_val_dash.split('-')[:2])]  # score_date_dash = '2022-09-30'\n",
    "\n",
    "#set up df_train and df_test (add 'target')\n",
    "df_target_test['ban'] = df_target_test['ban'].astype('int64')\n",
    "df_target_test = df_target_test.groupby('ban').tail(1)\n",
    "\n",
    "df_test = df_test.merge(df_target_test[['ban', 'product_crosssell_ind']], on='ban', how='left')\n",
    "df_test.rename(columns={'product_crosssell_ind': 'target'}, inplace=True)\n",
    "df_test.dropna(subset=['target'], inplace=True)\n",
    "df_test['target'] = df_test['target'].astype(int)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62170f7-10b3-47f6-9610-7d758e68b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e602c-d3dd-4748-9617-410bc68b193e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
