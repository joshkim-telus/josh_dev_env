{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47765a-79a6-4c08-b3ad-3466774a697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag cell with parameters\n",
    "PROJECT_ID =  'divg-groovyhoon-pr-d2eab4'\n",
    "DATASET_ID = 'nba_features_prospect'\n",
    "TABLE_ID = 'master_features_set_prospect_train_vw'\n",
    "RESOURCE_BUCKET = 'divg-groovyhoon-pr-d2eab4-default'\n",
    "FILE_BUCKET = 'divg-groovyhoon-pr-d2eab4_hs_nba_prospects' # change\n",
    "REGION = 'northamerica-northeast1'\n",
    "MODEL_ID = '7002' # change\n",
    "STACK_NAME = 'ffh_nba'\n",
    "MODEL_NAME = 'hs_nba_prospects' # change \n",
    "SERVICE_TYPE = 'hs_nba_prospects' # change\n",
    "SERVICE_TYPE_NAME = 'hs-nba-prospects' # change\n",
    "PIPELINE_TYPE='training_pipeline'\n",
    "PIPELINE_PATH = 'vertex_pipelines/hs_nba_prospects/serving_pipeline' # change\n",
    "HS_NBA_UTILS_PATH = 'vertex_pipelines/hs_nba_utils/notebook' \n",
    "MODEL_TYPE='acquisition' # change \n",
    "LOAD_SQL='load_train_data.sql'\n",
    "PREPROCESS_OUTPUT_CSV='df_train.csv' \n",
    "SAVE_FILE_NAME='df_test_exp.csv'\n",
    "STATS_FILE_NAME='df_stats.csv'\n",
    "AGGREGATE_RESULTS_TABLE_ID= 'bq_product_recommendation_ranked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae44f4-97ae-49ed-94c2-dfb728c3f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = PROJECT_ID\n",
    "dataset_id = DATASET_ID\n",
    "aggregate_results_table_id = AGGREGATE_RESULTS_TABLE_ID \n",
    "resource_bucket = RESOURCE_BUCKET\n",
    "stack_name = STACK_NAME\n",
    "pipeline_path = PIPELINE_PATH\n",
    "hs_nba_utils_path = HS_NBA_UTILS_PATH\n",
    "model_type=MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b8ff3-ac65-42af-8232-d4e0fa90edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import global modules\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from pathlib import Path\n",
    "from yaml import safe_load\n",
    "import sys\n",
    "import os\n",
    "from typing import Any\n",
    "# global import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set global vars\n",
    "pth_project = Path(os.getcwd())\n",
    "pth_output_table_config = pth_project / 'output_table_config.yaml'\n",
    "pth_queries = pth_project / 'queries'\n",
    "sys.path.insert(0, pth_project.as_posix())\n",
    "\n",
    "# init gcp clients\n",
    "storage_client = storage.Client()\n",
    "bq_client = bigquery.Client(project=project_id)\n",
    "\n",
    "def extract_dir_from_bucket(\n",
    "    bucket: Any, local_path: Path, prefix: str, split_prefix: str = 'serving_pipeline' \n",
    "):    \n",
    "    \"\"\"\n",
    "    Download files from a specified bucket to a local path, excluding a specified prefix.\n",
    "\n",
    "    Parameters:\n",
    "    - bucket: The bucket object from which to download files.\n",
    "    - local_path: The local path where the files will be downloaded to.\n",
    "    - prefix: The prefix to filter the files in the bucket. Only files with this prefix will be downloaded.\n",
    "    - split_prefix: The prefix to exclude from the downloaded file paths. Default is 'serving_pipeline'.\n",
    "    \"\"\"\n",
    "    for blob in bucket.list_blobs(prefix=prefix):\n",
    "        if not blob.name.endswith(\"/\"):\n",
    "            path = local_path / blob.name.split(f'{split_prefix}/')[-1]\n",
    "            str_path = path.as_posix()\n",
    "            Path(str_path[:str_path.rindex('/')]).mkdir(parents=True, exist_ok=True)\n",
    "            blob.download_to_filename(str_path)\n",
    "\n",
    "# download utils and output table config locally\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(resource_bucket)\n",
    "extract_dir_from_bucket(\n",
    "    bucket, pth_project, f'{stack_name}/{hs_nba_utils_path}', split_prefix='notebook'\n",
    ")\n",
    "extract_dir_from_bucket(\n",
    "    bucket, pth_project, f'{stack_name}/{pipeline_path}/queries'\n",
    ")\n",
    "blob = bucket.blob(f'{stack_name}/{pipeline_path}/output_table_config.yaml')\n",
    "blob.download_to_filename(pth_output_table_config)\n",
    "\n",
    "# import local modules\n",
    "from hs_nba_utils.etl.extract import extract_bq_data\n",
    "from hs_nba_utils.etl.load import create_temp_table, insert_from_temp_table\n",
    "\n",
    "# load output table config\n",
    "d_output_table_config = safe_load(pth_output_table_config.open())\n",
    "\n",
    "# load scores from bq\n",
    "pth_extract_scores = pth_queries / 'extract_model_scores.sql'\n",
    "df_scores = extract_bq_data(bq_client, pth_query=pth_extract_scores)\n",
    "\n",
    "# # postprocess output\n",
    "# df_to_load = build_output_dataframe(df_scores, d_output_table_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417a835-d986-4d45-ac91-e26a8e6fbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_scores\n",
    "d_data_config = d_output_table_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762de568-afc2-4c76-aa95-fe4819910d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9360ee2-9653-4d2f-bd32-a5346bc59a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Builds the output dataframe based on the input dataframe and data configuration.\n",
    "\n",
    "Args:\n",
    "    df (pd.DataFrame): The input dataframe.\n",
    "    d_data_config (dict): The data configuration dictionary.\n",
    "\n",
    "Returns:\n",
    "    pd.DataFrame: The output dataframe.\n",
    "\n",
    "\"\"\"\n",
    "##########\n",
    "# Rank main target variables\n",
    "##########\n",
    "# extract main target names from data config dictionary\n",
    "l_targets = [target['name'] for target in d_data_config['target_variables']]\n",
    "print(f'Ranking {len(l_targets)} main variables')\n",
    "\n",
    "# build target name - index mapping from targets\n",
    "d_target_idx_mapping = {\n",
    "    idx: target_name\n",
    "    for idx, target_name in enumerate(l_targets)\n",
    "}\n",
    "\n",
    "# build reco rank columns from targets\n",
    "l_recos = [f'reco_{i}' for i, _ in enumerate(l_targets)]\n",
    "\n",
    "# sort scores of target variables in descending order\n",
    "np_scores = df[l_targets].to_numpy()\n",
    "target_ranked = np.argsort(-np_scores, axis=1)    \n",
    "df[l_recos] = target_ranked\n",
    "# loop over reco columns and map idx to target names\n",
    "for reco in l_recos:\n",
    "    df[reco] = df[reco].map(d_target_idx_mapping)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf535c05-ba1f-4ae6-b400-23fbc275f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ban'] == 37714603][l_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390103bd-b323-404b-9898-0231afa0ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########\n",
    "# Add combos:\n",
    "#  - with 3 products -> check top 3 recos\n",
    "#  - with 2 products -> check top 2 recos\n",
    "##########\n",
    "print('Adding combos')\n",
    "# extract distinct number of products in combos\n",
    "unique_number_of_product_in_combos = set([\n",
    "    len(combo['target_variables']) for combo in d_data_config['combos']\n",
    "])\n",
    "## --> unique_number_of_product_in_combos = {2, 3}\n",
    "\n",
    "# extract unique name of products in combos\n",
    "unique_combo_target_names = set([\n",
    "    target \n",
    "    for combo in d_data_config['combos'] for target in combo['target_variables']\n",
    "])\n",
    "## --> unique_combo_target_names = {'shs_acquisition', 'ttv_acquisition', 'hsic_acquisition'}\n",
    "\n",
    "# check if product is in top n, for each product in combos\n",
    "for target_name in unique_combo_target_names:\n",
    "    for n in unique_number_of_product_in_combos:\n",
    "        df[f'is_{target_name}_in_top_{n}'] = (df[l_recos[:n]] == target_name).any(axis=1)\n",
    "\n",
    "# loop over combos\n",
    "for combo in d_data_config['combos']:\n",
    "    print(f\"Combo: {combo['name']}\")\n",
    "\n",
    "    # set n to check for recommendation combo\n",
    "    n = len(combo['target_variables'])\n",
    "\n",
    "    # extract columns to check condition\n",
    "    l_columns_to_check_combo_condition = [\n",
    "        f'is_{target_name}_in_top_{n}'\n",
    "        for target_name in combo['target_variables']\n",
    "    ]\n",
    "    \n",
    "    ## --> l_columns_to_check_combo_condition = ['is_hsic_acquisition_in_top_3', 'is_ttv_acquisition_in_top_3', 'is_shs_acquisition_in_top_3']\n",
    "\n",
    "    # define condition: all targets must be in top n recos\n",
    "    # condition = df[l_columns_to_check_combo_condition].all(axis=1)\n",
    "\n",
    "    \"\"\"\n",
    "    Combo Condition changed:\n",
    "        - Generate combo scores for all customers\n",
    "        - Combo score: exctract max score of products on combo \n",
    "    \"\"\"         \n",
    "    condition = True\n",
    "\n",
    "    # check condition: if condition pass, return max scores of targets \n",
    "    df[combo['name']] = np.where(\n",
    "        condition, df[combo['target_variables']].max(axis=1), 0\n",
    "    )\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a87d80-9bfd-48eb-9529-d7455e310784",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Rank scores again with combos included\n",
    "##########\n",
    "# extract combo target names from data config dictionary\n",
    "l_combo_targets = [combo['name'] for combo in d_data_config['combos']]\n",
    "print(f'Ranking {len(l_combo_targets)} combos variables')\n",
    "## --> l_combo_targets = ['hsic_tv_shs_combo_acquisition', 'hsic_tv_combo_acquisition', 'hsic_shs_combo_acquisition', 'tv_shs_combo_acquisition']\n",
    "\n",
    "# aggregate combos and main target names\n",
    "# order is important, so combos can be ranked fisrt when score\n",
    "# of combo is equal to the highest score of main targets\n",
    "l_targets_with_combos = l_combo_targets + l_targets\n",
    "print(f'Ranking {len(l_targets_with_combos)} total combos and main variables')\n",
    "## --> l_targets_with_combos = ['hsic_tv_shs_combo_acquisition', 'hsic_tv_combo_acquisition', 'hsic_shs_combo_acquisition', \n",
    "##                              'tv_shs_combo_acquisition', 'hsic_acquisition', 'ttv_acquisition', 'shs_acquisition', 'sing_acquisition', \n",
    "##                              'tos_acquisition', 'lwc_acquisition', 'sws_acquisition', 'wifi_acquisition', 'whsia_acquisition', 'hpro_acquisition']\n",
    "\n",
    "# rebuild target name - index mapping from targets including combos\n",
    "d_target_idx_mapping_with_combos = {\n",
    "    idx: target_name\n",
    "    for idx, target_name in enumerate(l_targets_with_combos)\n",
    "}\n",
    "## --> d_target_idx_mapping_with_combos = {0: 'hsic_tv_shs_combo_acquisition', 1: 'hsic_tv_combo_acquisition', 2: 'hsic_shs_combo_acquisition', \n",
    "##                                         3: 'tv_shs_combo_acquisition', 4: 'hsic_acquisition', 5: 'ttv_acquisition', \n",
    "##                                         6: 'shs_acquisition', 7: 'sing_acquisition', 8: 'tos_acquisition', \n",
    "##                                         9: 'lwc_acquisition', 10: 'sws_acquisition', 11: 'wifi_acquisition', \n",
    "##                                         12: 'whsia_acquisition', 13: 'hpro_acquisition'}\n",
    "\n",
    "# rebuild reco rank columns from targets including combos\n",
    "l_recos_with_combos = [f'reco_{i}' for i, _ in enumerate(l_targets_with_combos)]\n",
    "## --> l_recos_with_combos = ['reco_0', 'reco_1', 'reco_2', 'reco_3', 'reco_4', 'reco_5', 'reco_6', 'reco_7', 'reco_8', 'reco_9', 'reco_10', 'reco_11', 'reco_12', 'reco_13']\n",
    "\n",
    "# sort scores of combos and target variables in descending order\n",
    "np_scores = df[l_targets_with_combos].to_numpy()\n",
    "target_ranked = np.argsort(-np_scores, axis=1)\n",
    "df[l_recos_with_combos] = target_ranked\n",
    "\n",
    "# loop over reco columns and map idx to combo and target names\n",
    "for reco in l_recos_with_combos:\n",
    "    df[reco] = df[reco].map(d_target_idx_mapping_with_combos)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a70e93-8556-4c63-9d5b-295b90b6cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1acbb-3e5d-4024-87ac-d3b869eba712",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l_recos_with_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2412c6-9ea2-4ce2-9f39-d01dd4269fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##########\n",
    "# Explode columns to match output table format\n",
    "##########\n",
    "# extract columns intersection from data config dictionary and current dataframe\n",
    "l_intersection_cols = [\n",
    "    col for col in d_data_config['output_columns']\n",
    "    if col in df.columns\n",
    "]\n",
    "\n",
    "## --> l_intersection_cols = ['part_dt', 'cust_id', 'ban', 'ban_src_id', 'lpds_id']\n",
    "\n",
    "# extract unique tier names from data config dictionary\n",
    "unique_tier_names = set([\n",
    "    tier['name']\n",
    "    for tiers in d_data_config['tiers'].values() for tier in tiers\n",
    "])\n",
    "\n",
    "## --> unique_tier_names = {'hsic_ultimate_tier_acquisition', 'tos_ultimate_tier_acquisition', 'hsic_complete_tier_acquisition', 'tos_complete_tier_acquisition'}\n",
    "\n",
    "l_dfs = []\n",
    "# loop over recommendations and build output dataframe\n",
    "for i, reco in enumerate(l_recos_with_combos):\n",
    "    print(f'Processing {reco}')\n",
    "    \n",
    "    # build helper dataframe\n",
    "    df_helper = df[\n",
    "        l_intersection_cols + [reco] + list(unique_tier_names)\n",
    "    ].copy()\n",
    "    \n",
    "    # set rank and rename reco column\n",
    "    df_helper['rank'] = i + 1     \n",
    "    df_helper = df_helper.rename(columns={reco: 'product_name'})\n",
    "\n",
    "    # extract model scores\n",
    "    df_helper['score'] = df.lookup(df_helper.index, df_helper['product_name'])\n",
    "\n",
    "    l_dfs.append(df_helper)\n",
    "\n",
    "df_concat = pd.concat(l_dfs)\n",
    "print(f'Concat dataframe df.shape {df_concat.shape}')\n",
    "\n",
    "# remove rows with score zero, usually combos\n",
    "df_concat = df_concat[df_concat['score'] > 0]   \n",
    "print(f'Concat dataframe without zero scores df.shape {df_concat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4fef6-b9fb-4b54-b302-0958926a5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv('gs://divg-groovyhoon-pr-d2eab4-default/downloads/df_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8327a-e007-4856-857e-cba101d8d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat[df_concat['ban'] == 40331338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1cc2d0-21de-42ec-9c74-6b027559807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat[df_concat['product_name'] == 'tos_acquisition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993766ae-21ff-48d3-9bac-e789ff9a13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tier_name, l_tiers_values in d_data_config['tiers'].items():\n",
    "    print(f'tier_name: {tier_name}')\n",
    "    print(f'l_tiers_values: {l_tiers_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54313171-edbe-47df-af0c-caceef731bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tier_name, l_tiers_values in d_data_config['tiers'].items():\n",
    "    for i, d_tier in enumerate(l_tiers_values):\n",
    "        print(f'i: {i}')\n",
    "        print(f'd_tier: {d_tier}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197a249-c9d7-4995-990d-e8c5ed7adcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########\n",
    "# Add tiers\n",
    "##########\n",
    "# create a new column to store tier results\n",
    "df_concat['product_name_tier'] = df_concat['product_name']\n",
    "\n",
    "df_concat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784087e-2a5f-4c15-acc7-6ef0fb50aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_data_config['tiers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b050c9-270f-416c-875a-4d2a45c756f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########\n",
    "# Add tiers\n",
    "##########\n",
    "# create a new column to store tier results\n",
    "df_concat['product_name_tier'] = df_concat['product_name']\n",
    "\n",
    "# loop over tiers\n",
    "for tier_name, l_tiers_values in d_data_config['tiers'].items():\n",
    "\n",
    "    # set conditions to edit dataframe\n",
    "    conditions = (df_concat['product_name'] == tier_name)\n",
    "    print(f'Processing tier: {tier_name}')\n",
    "\n",
    "    # loop over tier targets\n",
    "    for i, d_tier in enumerate(l_tiers_values):\n",
    "        print(f\"Tier: {d_tier['name']}\")\n",
    "\n",
    "        # first iteration: only add tier scores to column\n",
    "        if i == 0:\n",
    "            df_concat['product_name_tier'] = np.where(\n",
    "                conditions, d_tier['name'], df_concat['product_name_tier']\n",
    "            )\n",
    "            df_concat['tier_score'] = np.where(\n",
    "                conditions, df_concat[d_tier['name']], df_concat[d_tier['name']]\n",
    "            )\n",
    "\n",
    "        # update dataframe if new tier score is higher then previous tier scores\n",
    "        else:\n",
    "            update_conditions = conditions & (df_concat[d_tier['name']] > df_concat['tier_score'])\n",
    "            df_concat['product_name_tier'] = np.where(\n",
    "                update_conditions, d_tier['name'], df_concat['product_name_tier']\n",
    "            )\n",
    "            df_concat['tier_score'] = np.where(\n",
    "                update_conditions, df_concat[d_tier['name']], df_concat['tier_score']\n",
    "            ) \n",
    "\n",
    "# set tier zeros scores to None\n",
    "conditions = (df_concat['tier_score'] != 0)\n",
    "df_concat['tier_score'] = np.where(\n",
    "    conditions, df_concat['tier_score'], None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db59ba3-d09e-4a96-bf41-d959fe13666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat[df_concat['product_name_tier'] == 'tos_ultimate_tier_acquisition'].to_csv('gs://divg-groovyhoon-pr-d2eab4-default/downloads/df_concat_tos_u.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88886607-d9fb-4050-8368-1835f090723a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd757a-c5da-4b34-b3fc-b630530a9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########\n",
    "# Map target names to their abbreviation name\n",
    "##########\n",
    "print('Mapping target name with reco name')\n",
    "# extract main target name - reco mapping\n",
    "d_main_target_reco_mapping = {\n",
    "    target['name']: target['reco']\n",
    "    for target in d_data_config['target_variables']\n",
    "}\n",
    "\n",
    "# extract tier target name - reco mapping\n",
    "d_tier_target_reco_mapping = {\n",
    "    tier['name']: tier['reco']\n",
    "    for tiers in d_data_config['tiers'].values() for tier in tiers\n",
    "}\n",
    "\n",
    "# extract combos target name - reco mapping\n",
    "d_combo_target_reco_mapping = {\n",
    "    combo['name']: combo['reco']\n",
    "    for combo in d_data_config['combos']\n",
    "}\n",
    "\n",
    "# create final mapping dictionary\n",
    "d_target_reco_mapping = {}\n",
    "for d_map in (d_main_target_reco_mapping, d_tier_target_reco_mapping, d_combo_target_reco_mapping):\n",
    "    d_target_reco_mapping.update(d_map)\n",
    "\n",
    "# map names and recos\n",
    "df_concat['reco'] = df_concat['product_name_tier'].map(d_target_reco_mapping)\n",
    "\n",
    "# select output columns\n",
    "df_output = df_concat[d_data_config['output_columns']]\n",
    "df_output['product_name'] = df_concat['product_name_tier']\n",
    "print(f'Final dataframe df.shape {df_output.shape}')\n",
    "\n",
    "return df_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c7d6d-235f-4225-a503-d2e96b77edd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
