{
  "pipelineSpec": {
    "components": {
      "comp-bq-create-dataset": {
        "executorLabel": "exec-bq-create-dataset",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "environment": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            },
            "score_date": {
              "type": "STRING"
            },
            "score_date_delta": {
              "type": "INT"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-bq-create-dataset-2": {
        "executorLabel": "exec-bq-create-dataset-2",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "environment": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            },
            "score_date": {
              "type": "STRING"
            },
            "score_date_delta": {
              "type": "INT"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "col_list": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-generate-data-stats": {
        "executorLabel": "exec-generate-data-stats",
        "inputDefinitions": {
          "parameters": {
            "bucket_nm": {
              "type": "STRING"
            },
            "data_type": {
              "type": "STRING"
            },
            "date_col": {
              "type": "STRING"
            },
            "date_filter": {
              "type": "STRING"
            },
            "dest_schema_path": {
              "type": "STRING"
            },
            "dest_stats_bq_dataset": {
              "type": "STRING"
            },
            "dest_stats_gcs_path": {
              "type": "STRING"
            },
            "in_bq_ind": {
              "type": "STRING"
            },
            "model_nm": {
              "type": "STRING"
            },
            "model_type": {
              "type": "STRING"
            },
            "op_type": {
              "type": "STRING"
            },
            "pass_through_features": {
              "type": "STRING"
            },
            "pred_cols": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "row_sample": {
              "type": "DOUBLE"
            },
            "src_bq_path": {
              "type": "STRING"
            },
            "src_csv_path": {
              "type": "STRING"
            },
            "table_block_sample": {
              "type": "DOUBLE"
            },
            "token": {
              "type": "STRING"
            },
            "training_target_col": {
              "type": "STRING"
            },
            "update_ts": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "statistics": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-preprocess": {
        "executorLabel": "exec-preprocess",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "pipeline_dataset": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "score_date_dash": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-preprocess-2": {
        "executorLabel": "exec-preprocess-2",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "pipeline_dataset": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "save_data_path": {
              "type": "STRING"
            },
            "score_date_dash": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-train-and-save-model": {
        "executorLabel": "exec-train-and-save-model",
        "inputDefinitions": {
          "parameters": {
            "dataset_id": {
              "type": "STRING"
            },
            "file_bucket": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "service_type": {
              "type": "STRING"
            },
            "token": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "metricsc": {
              "artifactType": {
                "schemaTitle": "system.ClassificationMetrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "col_list": {
              "type": "STRING"
            },
            "model_uri": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-upload-model": {
        "executorLabel": "exec-upload-model",
        "inputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "col_list": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "model_uri": {
              "type": "STRING"
            },
            "prediction_image": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "vertex_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "model_uri": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-visualize-stats": {
        "executorLabel": "exec-visualize-stats",
        "inputDefinitions": {
          "artifacts": {
            "statistics": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "base_stats_nm": {
              "type": "STRING"
            },
            "op_type": {
              "type": "STRING"
            },
            "stats_nm": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "view": {
              "artifactType": {
                "schemaTitle": "system.HTML",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-bq-create-dataset": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_create_dataset"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_create_dataset(score_date: str\n                      , score_date_delta: int\n                      , project_id: str\n                      , dataset_id: str\n                      , region: str\n                      , environment: str\n                      , token: str\n                      ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            DECLARE score_date DATE DEFAULT \"{score_date}\";\n\n            -- Change dataset / sp name to the version in the bi_layer\n            CALL {dataset_id}.bq_sp_c12m_{environment}_dataset(score_date);\n\n            SELECT\n                *\n            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n            WHERE table_name='bq_c12m_{environment}_dataset'\n\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n    logging.info(df.to_string())\n\n    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]} on \\\n             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d %H:%M:%S') } !\")\n\n    ######################################## Save column list_##########################\n    query =\\\n        f'''\n           SELECT\n                *\n            FROM {dataset_id}.bq_c12m_{environment}_dataset\n\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    col_list = list([col for col in df.columns])\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 4.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-bq-create-dataset-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "bq_create_dataset"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef bq_create_dataset(score_date: str\n                      , score_date_delta: int\n                      , project_id: str\n                      , dataset_id: str\n                      , region: str\n                      , environment: str\n                      , token: str\n                      ) -> NamedTuple(\"output\", [(\"col_list\", list)]):\n\n    from google.cloud import bigquery\n    import logging \n    from datetime import datetime\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    # Change dataset / table + sp table name to version in bi-layer\n    query =\\\n        f'''\n            DECLARE score_date DATE DEFAULT \"{score_date}\";\n\n            -- Change dataset / sp name to the version in the bi_layer\n            CALL {dataset_id}.bq_sp_c12m_{environment}_dataset(score_date);\n\n            SELECT\n                *\n            FROM {dataset_id}.INFORMATION_SCHEMA.PARTITIONS\n            WHERE table_name='bq_c12m_{environment}_dataset'\n\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n    logging.info(df.to_string())\n\n    logging.info(f\"Loaded {df.total_rows[0]} rows into \\\n             {df.table_catalog[0]}.{df.table_schema[0]}.{df.table_name[0]} on \\\n             {datetime.strftime((df.last_modified_time[0]), '%Y-%m-%d %H:%M:%S') } !\")\n\n    ######################################## Save column list_##########################\n    query =\\\n        f'''\n           SELECT\n                *\n            FROM {dataset_id}.bq_c12m_{environment}_dataset\n\n        '''\n\n    df = client.query(query, job_config=job_config).to_dataframe()\n\n    col_list = list([col for col in df.columns])\n    return (col_list,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 4.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-generate-data-stats": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "generate_data_stats"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef generate_data_stats(\n    project_id: str,\n    data_type: str,\n    op_type: str,\n    model_nm: str,\n    update_ts: str,\n    token: str, \n    statistics: Output[Artifact],\n    bucket_nm: str = '',\n    model_type: str = 'supervised',\n    date_col: str = '',\n    date_filter: str = '',\n    table_block_sample: float = 1,\n    row_sample: float = 1,\n    in_bq_ind: bool = True,\n    src_bq_path: str = '',\n    src_csv_path: str = '',\n    dest_stats_bq_dataset: str = '',\n    dest_schema_path: str = '',\n    dest_stats_gcs_path: str = '',\n    pass_through_features: list = [],\n    training_target_col: str = \"\",\n    pred_cols: list = []\n):\n    '''\n    Inputs:\n        - project_id: project id\n        - data_type: bigquery or csv\n        - op_type: training or serving or predictions\n        - model_nm: name of model\n        - update_ts: time when pipeline was run\n        - bucket_nm: name of bucket where pred schema is or will be stored (Optional: for predictions)\n        - model_type: supervised or unsupervised. unsupervised models will create new schema as required.\n        - date_col: (Optional: name of column for filtering data by date)\n        - date_filter: YYYY-MM-DD (Optional: query only specific date for stats)\n        - table_block_sample: sample of data blocks to be loaded (only if bq). Reduces query size for large datasets. 0.1 for 10% (default is 1)\n        - row_sample: sample of rows to be loaded (only if bq). If using table_block_sample as well, this will be the % of rows from the selected blocks.\n          0.1 for 10% (default is 1)\n        - in_bq_ind: True or False (Optional: store stats in bigquery)\n        - src_bq_path: bigquery path to data that will be used to generate stats (if data_type is bigquery)\n        - src_csv_path: path to csv file that will be used to generate stats (if data_type is csv)\n        - dest_stats_bq_dataset: bq dataset where monitoring stats will be stored (only if in_bq_path set to True)\n        - dest_schema_path: gcs path to where schema will be stored (optional: only for training stats)\n        - dest_stats_gcs_path: gcs path to where stats should be stored\n        - pass_through_features: list of feature columns not used for training e.g. keys and ids \n        - training_target_col: target column name from training data (Optional: set to be excluded from serving data)\n        - pred_cols: column names where predictions are stored\n\n    Outputs:\n        - statistics\n    '''\n\n    import tensorflow_data_validation as tfdv\n    from apache_beam.options.pipeline_options import (\n        PipelineOptions\n    )\n    from google.cloud import storage\n    from google.cloud import bigquery\n    from datetime import datetime\n    import json\n    import pandas as pd\n    import numpy as np\n    import google.oauth2.credentials\n\n    # convert timestamp to datetime\n    update_ts = datetime.strptime(update_ts, '%Y-%m-%d %H:%M:%S')\n\n    statistics.uri = dest_stats_gcs_path\n\n    pipeline_options = PipelineOptions()\n    stats_options = tfdv.StatsOptions()\n\n    # import from csv in GCS\n    if data_type == 'csv':\n        df = pd.read_csv(src_csv_path)\n\n        if op_type == 'predictions':\n            df = df[pred_cols]\n\n    # import from Big Query\n    elif data_type == 'bigquery':\n\n        percent_table_sample = table_block_sample * 100\n\n        if op_type == 'predictions':\n            # query data stored in BQ and load into pandas dataframe\n            build_df = '''SELECT '''\n            for pred_col in pred_cols:\n                build_df = build_df + f\"{pred_col}, \"\n            build_df = build_df + '''FROM `{bq_table}` TABLESAMPLE SYSTEM ({percent_table_sample} PERCENT)\n                        WHERE rand() < {row_sample} \n                    '''.format(bq_table = src_bq_path,\n                               percent_table_sample = percent_table_sample, \n                               row_sample = row_sample)\n        else:\n            # query data stored in BQ and load into pandas dataframe\n            build_df = '''\n            SELECT * FROM `{bq_table}` TABLESAMPLE SYSTEM ({percent_table_sample} PERCENT)\n                        WHERE rand() < {row_sample} \n                    '''.format(bq_table = src_bq_path,\n                               percent_table_sample = percent_table_sample, \n                               row_sample = row_sample)\n\n        if len(date_filter) > 0:\n            build_df = build_df + ''' AND {date_col}=\"{date_filter}\"\n            '''.format(date_col=date_col, date_filter=date_filter)\n\n        job_config = bigquery.QueryJobConfig()\n        df = client.query(build_df, job_config=job_config).to_dataframe()\n\n        # check this: if dataframe is empty, return error\n        if (df.size == 0):\n            raise TypeError(\"Dataframe is empty, cannot generate statistics.\")\n\n    else:\n        print(\"This data type is not supported. Please use a csv or Big Query table, otherwise create your own custom component\")\n\n    # drop pass-through features\n    if len(pass_through_features) > 0:\n        df = df.drop(columns=pass_through_features)\n\n    stats = tfdv.generate_statistics_from_dataframe(\n        dataframe=df,\n        stats_options=stats_options,\n        n_jobs=1\n    )\n    tfdv.write_stats_text(\n        stats=stats, \n        output_path=dest_stats_gcs_path\n    )\n\n    # generate schema for training data\n    if op_type == 'training':\n        schema = tfdv.infer_schema(stats)\n\n        if 'TRAINING' not in schema.default_environment:\n                schema.default_environment.append('TRAINING')\n\n        # set training target column for supervised learning models (will not be in serving data)\n        if model_type == 'supervised':\n            if 'SERVING' not in schema.default_environment:\n                schema.default_environment.append('SERVING')\n\n            # check if training_target_col specified\n            if len(training_target_col) > 0:\n                # specify that target/label is not in SERVING environment\n                if 'SERVING' not in tfdv.get_feature(schema, training_target_col).not_in_environment:\n                    tfdv.get_feature(\n                        schema, training_target_col).not_in_environment.append('SERVING') \n            else:\n                print(\"No training target column specified\")\n\n        tfdv.write_schema_text(\n            schema=schema, output_path=dest_schema_path\n        )\n\n    if (op_type == 'predictions') | (model_type == 'unsupervised'):\n        # if schema does not exist create new one for predictions or unsupervised model\n        storage_client = storage.Client()\n        bucket = storage_client.bucket(bucket_nm)\n        blob = bucket.blob(dest_schema_path.split(f'gs://{bucket_nm}/')[1])\n\n        if not blob.exists():\n            # generate schema for predictions data or unsupervised learning model\n            schema = tfdv.infer_schema(stats)\n            tfdv.write_schema_text(\n                schema=schema, output_path=dest_schema_path\n            )\n\n    df_stats = pd.DataFrame(columns=['model_nm',\n                                     'update_ts',\n                                     'op_type',\n                                     'feature_nm',\n                                     'feature_type',\n                                     'num_non_missing',\n                                     'min_num_values',\n                                     'max_num_values',\n                                     'avg_num_values',\n                                     'tot_num_values',\n                                     'mean',\n                                     'std_dev',\n                                     'num_zeros',\n                                     'min_val',\n                                     'median',\n                                     'max_val',\n                                     'unique_values',\n                                     'top_value_freq',\n                                     'avg_length'])\n\n    # OPTIONAL: save stats in data monitoring table\n    if in_bq_ind == True:\n\n        for feature in stats.datasets[0].features:\n            feature_nm = feature.path.step[0]\n            if (feature.type == 0):\n                feature_type = 'INT'\n            elif (feature.type == 1):\n                feature_type = 'FLOAT'\n            elif (feature.type == 2):\n                feature_type = 'STRING'\n            else:\n                featue_type = 'UNKNOWN'\n\n            if (feature_type == 'INT') | (feature_type == 'FLOAT'):\n                num_non_missing = feature.num_stats.common_stats.num_non_missing\n                min_num_values = feature.num_stats.common_stats.min_num_values\n                max_num_values = feature.num_stats.common_stats.max_num_values\n                avg_num_values = feature.num_stats.common_stats.avg_num_values\n                tot_num_values = feature.num_stats.common_stats.tot_num_values\n\n                mean = feature.num_stats.mean\n                std_dev = feature.num_stats.std_dev\n                num_zeros = feature.num_stats.num_zeros\n                min_val = feature.num_stats.min\n                median = feature.num_stats.median\n                max_val = feature.num_stats.max\n\n                df_stats.loc[len(df_stats.index)] = pd.Series({\n                    'model_nm': model_nm,\n                    'update_ts': update_ts,\n                    'op_type': op_type,\n                    'feature_nm': feature_nm,\n                    'feature_type': feature_type,\n                    'num_non_missing': num_non_missing,\n                    'min_num_values': min_num_values,\n                    'max_num_values': max_num_values,\n                    'avg_num_values': avg_num_values,\n                    'tot_num_values': tot_num_values,\n                    'mean': mean,\n                    'std_dev': std_dev,\n                    'num_zeros': num_zeros,\n                    'min_val': min_val,\n                    'median': median,\n                    'max_val': max_val\n                })\n\n            elif feature_type == 'STRING':\n                num_non_missing = feature.string_stats.common_stats.num_non_missing\n                min_num_values = feature.string_stats.common_stats.min_num_values\n                max_num_values = feature.string_stats.common_stats.max_num_values\n                avg_num_values = feature.string_stats.common_stats.avg_num_values\n                tot_num_values = feature.string_stats.common_stats.tot_num_values\n\n                unique_values = feature.string_stats.unique\n\n                # create dict of top values to be stored in BQ as record\n                top_values = feature.string_stats.top_values\n                top_value_freq_arr = []\n                for i in range(len(top_values)):\n                    top_value = top_values[i]\n                    value = top_value.value\n                    freq = top_value.frequency\n                    top_value_dict = {'value': value, 'frequency': freq}\n                    top_value_freq_arr.append(top_value_dict)\n\n                avg_length = feature.string_stats.avg_length\n\n                df_stats.loc[len(df_stats.index)] = pd.Series({\n                    'model_nm': model_nm,\n                    'update_ts': update_ts,\n                    'op_type': op_type,\n                    'feature_nm': feature_nm,\n                    'feature_type': feature_type,\n                    'num_non_missing': num_non_missing,\n                    'min_num_values': min_num_values,\n                    'max_num_values': max_num_values,\n                    'avg_num_values': avg_num_values,\n                    'tot_num_values': tot_num_values,\n                    'unique_values': unique_values,\n                    'top_value_freq': top_value_freq_arr,\n                    'avg_length': avg_length\n                })\n\n        # set null records to None value\n        df_stats['top_value_freq'] = df_stats['top_value_freq'].fillna(np.nan).replace([\n            np.nan], [None])\n\n#         #### For wb\n#         CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n#         client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n\n        #### For prod \n        client = bigquery.Client(project=project_id)\n\n        job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\",\n                                            schema=[\n                                                bigquery.SchemaField(\n                                                    \"model_nm\", \"STRING\"),\n                                                bigquery.SchemaField(\n                                                    \"update_ts\", \"TIMESTAMP\"),\n                                                bigquery.SchemaField(\n                                                    \"op_type\", \"STRING\"),\n                                                bigquery.SchemaField(\n                                                    \"feature_nm\", \"STRING\"),\n                                                bigquery.SchemaField(\n                                                    \"feature_type\", \"STRING\"),\n                                                bigquery.SchemaField(\n                                                    \"num_non_missing\", \"INTEGER\"),\n                                                bigquery.SchemaField(\n                                                    \"min_num_values\", \"INTEGER\"),\n                                                bigquery.SchemaField(\n                                                    \"max_num_values\", \"INTEGER\"),\n                                                bigquery.SchemaField(\n                                                    \"avg_num_values\", \"FLOAT\"),\n                                                bigquery.SchemaField(\n                                                    \"tot_num_values\", \"INTEGER\"),\n                                                bigquery.SchemaField(\n                                                    \"mean\", \"FLOAT\"),\n                                                bigquery.SchemaField(\n                                                    \"std_dev\", \"FLOAT\"),\n                                                bigquery.SchemaField(\n                                                    \"num_zeros\", \"INTEGER\"),\n                                                bigquery.SchemaField(\n                                                    \"min_val\", \"FLOAT\"),\n                                                bigquery.SchemaField(\n                                                    \"median\", \"FLOAT\"),\n                                                bigquery.SchemaField(\n                                                    \"max_val\", \"FLOAT\"),\n                                                bigquery.SchemaField(\n                                                    \"unique_values\", \"FLOAT\"),\n                                                bigquery.SchemaField(\"top_value_freq\", \"RECORD\", mode=\"REPEATED\", fields=[\n                                                    bigquery.SchemaField(\"frequency\", \"FLOAT\"), bigquery.SchemaField(\"value\", \"STRING\")]),\n                                                bigquery.SchemaField(\n                                                    \"avg_length\", \"FLOAT\")\n                                            ],)  # create new table or append if already exists\n\n        data_stats_table = f\"{project_id}.{dest_stats_bq_dataset}.bq_data_monitoring\"\n\n        job = client.load_table_from_dataframe(# Make an API request.\n            df_stats, data_stats_table, job_config=job_config\n        )\n        job.result()\n        table = client.get_table(data_stats_table)  # Make an API request.\n        print(\n            \"Loaded {} rows and {} columns to {}\".format(\n                table.num_rows, len(table.schema), data_stats_table\n            )\n        )\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-tfdv-slim:1.0.0",
            "resources": {
              "cpuLimit": 4.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-preprocess": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "preprocess"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef preprocess(pipeline_dataset: str\n               , save_data_path: str\n               , project_id: str\n               , dataset_id: str\n               , score_date_dash: str\n               ):\n\n    from google.cloud import bigquery\n    import pandas as pd\n    import numpy as np\n    import gc\n    import time\n\n    client = bigquery.Client(project=project_id)\n\n    # pipeline_dataset \n    pipeline_dataset_name = f\"{project_id}.{dataset_id}.{pipeline_dataset}\" \n    build_df_pipeline_dataset = f'SELECT * FROM `{pipeline_dataset_name}`'\n    df_pipeline_dataset = client.query(build_df_pipeline_dataset).to_dataframe()\n    df_pipeline_dataset = df_pipeline_dataset.set_index('ban') \n\n    # demo columns\n    df_pipeline_dataset['demo_urban_flag'] = df_pipeline_dataset.demo_sgname.str.lower().str.contains('urban').fillna(0).astype(int)\n    df_pipeline_dataset['demo_rural_flag'] = df_pipeline_dataset.demo_sgname.str.lower().str.contains('rural').fillna(0).astype(int)\n    df_pipeline_dataset['demo_family_flag'] = df_pipeline_dataset.demo_lsname.str.lower().str.contains('families').fillna(0).astype(int)\n\n    df_income_dummies = pd.get_dummies(df_pipeline_dataset[['demo_lsname']]) \n    df_income_dummies.columns = df_income_dummies.columns.str.replace('&', 'and')\n    df_income_dummies.columns = df_income_dummies.columns.str.replace(' ', '_')\n\n    df_pipeline_dataset.drop(columns=['demo_sgname', 'demo_lsname'], axis=1, inplace=True)\n\n    df_pipeline_dataset = df_pipeline_dataset.join(df_income_dummies)\n\n    df_join = df_pipeline_dataset.copy()\n\n    #column name clean-up\n    df_join.columns = df_join.columns.str.replace(' ', '_')\n    df_join.columns = df_join.columns.str.replace('-', '_')\n\n    # set up df_target \n    sql_target = ''' SELECT * FROM `{}.{}.bq_churn_12_months_targets` '''.format(project_id, dataset_id) \n    df_target = client.query(sql_target).to_dataframe()\n    df_target = df_target.loc[\n        df_target['YEAR_MONTH'] == '-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n    df_target['ban'] = df_target['ban'].astype('int64')\n    df_target = df_target.groupby('ban').tail(1)\n\n    # set up df_final\n    df_final = df_join.merge(df_target[['ban', 'target_ind']], on='ban', how='left')\n    df_final.rename(columns={'target_ind': 'target'}, inplace=True) \n    df_final['target'].fillna(0, inplace=True) \n    df_final['target'] = df_final['target'].astype(int) \n    print(df_final.shape)\n\n    # delete df_join\n    del df_join\n    gc.collect()\n    print('......df_final done')\n\n    for f in df_final.columns:\n        df_final[f] = list(df_final[f])\n\n    df_final.to_csv(save_data_path, index=True) \n    del df_final\n    gc.collect()\n    print(f'......csv saved in {save_data_path}')\n    time.sleep(120)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 64.0
            }
          }
        },
        "exec-preprocess-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "preprocess"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef preprocess(pipeline_dataset: str\n               , save_data_path: str\n               , project_id: str\n               , dataset_id: str\n               , score_date_dash: str\n               ):\n\n    from google.cloud import bigquery\n    import pandas as pd\n    import numpy as np\n    import gc\n    import time\n\n    client = bigquery.Client(project=project_id)\n\n    # pipeline_dataset \n    pipeline_dataset_name = f\"{project_id}.{dataset_id}.{pipeline_dataset}\" \n    build_df_pipeline_dataset = f'SELECT * FROM `{pipeline_dataset_name}`'\n    df_pipeline_dataset = client.query(build_df_pipeline_dataset).to_dataframe()\n    df_pipeline_dataset = df_pipeline_dataset.set_index('ban') \n\n    # demo columns\n    df_pipeline_dataset['demo_urban_flag'] = df_pipeline_dataset.demo_sgname.str.lower().str.contains('urban').fillna(0).astype(int)\n    df_pipeline_dataset['demo_rural_flag'] = df_pipeline_dataset.demo_sgname.str.lower().str.contains('rural').fillna(0).astype(int)\n    df_pipeline_dataset['demo_family_flag'] = df_pipeline_dataset.demo_lsname.str.lower().str.contains('families').fillna(0).astype(int)\n\n    df_income_dummies = pd.get_dummies(df_pipeline_dataset[['demo_lsname']]) \n    df_income_dummies.columns = df_income_dummies.columns.str.replace('&', 'and')\n    df_income_dummies.columns = df_income_dummies.columns.str.replace(' ', '_')\n\n    df_pipeline_dataset.drop(columns=['demo_sgname', 'demo_lsname'], axis=1, inplace=True)\n\n    df_pipeline_dataset = df_pipeline_dataset.join(df_income_dummies)\n\n    df_join = df_pipeline_dataset.copy()\n\n    #column name clean-up\n    df_join.columns = df_join.columns.str.replace(' ', '_')\n    df_join.columns = df_join.columns.str.replace('-', '_')\n\n    # set up df_target \n    sql_target = ''' SELECT * FROM `{}.{}.bq_churn_12_months_targets` '''.format(project_id, dataset_id) \n    df_target = client.query(sql_target).to_dataframe()\n    df_target = df_target.loc[\n        df_target['YEAR_MONTH'] == '-'.join(score_date_dash.split('-')[:2])]  # score_date_dash = '2022-08-31'\n    df_target['ban'] = df_target['ban'].astype('int64')\n    df_target = df_target.groupby('ban').tail(1)\n\n    # set up df_final\n    df_final = df_join.merge(df_target[['ban', 'target_ind']], on='ban', how='left')\n    df_final.rename(columns={'target_ind': 'target'}, inplace=True) \n    df_final['target'].fillna(0, inplace=True) \n    df_final['target'] = df_final['target'].astype(int) \n    print(df_final.shape)\n\n    # delete df_join\n    del df_join\n    gc.collect()\n    print('......df_final done')\n\n    for f in df_final.columns:\n        df_final[f] = list(df_final[f])\n\n    df_final.to_csv(save_data_path, index=True) \n    del df_final\n    gc.collect()\n    print(f'......csv saved in {save_data_path}')\n    time.sleep(120)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 8.0,
              "memoryLimit": 64.0
            }
          }
        },
        "exec-train-and-save-model": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "train_and_save_model"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef train_and_save_model(file_bucket: str\n                        , service_type: str\n                        , project_id: str\n                        , dataset_id: str\n                        , metrics: Output[Metrics]\n                        , metricsc: Output[ClassificationMetrics]\n                        , model: Output[Model]\n                        , token: str\n                        )-> NamedTuple(\"output\", [(\"col_list\", list), (\"model_uri\", str)]):\n\n    #### Import Libraries ####\n\n    telus_purple = '#4B286D'\n    telus_green = '#66CC00'\n    telus_grey = '#F4F4F7'\n\n    import os \n    import gc\n    import time\n    import pickle\n    import joblib\n    import logging \n    import pandas as pd\n    import numpy as np\n    import xgboost as xgb\n    import seaborn as sns\n\n    import matplotlib.pyplot as plt\n    import plotly.graph_objs as go\n    import plotly.express as px\n\n    from plotly.subplots import make_subplots\n    from datetime import datetime\n    from sklearn.metrics import roc_auc_score\n    from sklearn.preprocessing import normalize\n    from sklearn.model_selection import train_test_split\n    from google.cloud import storage\n    from google.cloud import bigquery\n\n    from pycaret.classification import setup,create_model,tune_model, predict_model,get_config,compare_models,save_model,tune_model, models\n    from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, mean_squared_error, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, classification_report\n    from pycaret.datasets import get_data\n\n    def get_lift(prob, y_test, q):\n        result = pd.DataFrame(columns=['Prob', 'Churn'])\n        result['Prob'] = prob\n        result['Churn'] = y_test\n        # result['Decile'] = pd.qcut(1-result['Prob'], 10, labels = False)\n        result['Decile'] = pd.qcut(result['Prob'], q, labels=[i for i in range(q, 0, -1)])\n        add = pd.DataFrame(result.groupby('Decile')['Churn'].mean()).reset_index()\n        add.columns = ['Decile', 'avg_real_churn_rate']\n        result = result.merge(add, on='Decile', how='left')\n        result.sort_values('Decile', ascending=True, inplace=True)\n        lg = pd.DataFrame(result.groupby('Decile')['Prob'].mean()).reset_index()\n        lg.columns = ['Decile', 'avg_model_pred_churn_rate']\n        lg.sort_values('Decile', ascending=False, inplace=True)\n        lg['avg_churn_rate_total'] = result['Churn'].mean()\n        lg['total_churn'] = result['Churn'].sum()\n        lg = lg.merge(add, on='Decile', how='left')\n        lg['lift'] = lg['avg_real_churn_rate'] / lg['avg_churn_rate_total']\n\n        return lg\n\n    def create_folder_if_not_exists(path):\n        \"\"\"\n        Create a new folder based on a path if that path does not currently exist.\n        \"\"\"\n        if not os.path.exists(path):\n            os.makedirs(path)\n            print(f\"Folder created: {path}\")\n        else:\n            print(f\"Folder already exists: {path}\")\n\n    def ploty_model_metrics(actual, predicted, plot=False):\n        f1_score_ = f1_score(actual, predicted)\n        recall_score_ = recall_score(actual, predicted)\n        acc_score_ = accuracy_score(actual, predicted)\n        pr_score_ = precision_score(actual, predicted)\n\n        metrics_df = pd.DataFrame(data=[[acc_score_, pr_score_,recall_score_, f1_score_,]],\n                                  columns=['Accuracy', 'Precision', 'Recall', 'F1_score'])\n\n        trace = go.Bar(x = (metrics_df.T[0].values), \n                        y = list(metrics_df.columns), \n                        text = np.round_(metrics_df.T[0].values,4),\n                        textposition = 'auto',\n                        orientation = 'h', \n                        opacity = 0.8,\n                        marker=dict(\n                                    color=[telus_purple] * 4,\n                                    line=dict(color='#000000',width=1.5)\n                                )\n                       )\n        fig = go.Figure()\n        fig.add_trace(trace)\n        fig.update_layout(title='Model Metrics')\n\n        if plot:\n            fig.show()\n        return  metrics_df, fig\n\n    def plotly_confusion_matrix(actual, \n                                predicted, \n                                axis_labels='',\n                                plot=False):\n        cm=confusion_matrix(actual, predicted)\n\n        if axis_labels=='':\n            x = [str(x) for x in range(pd.Series(actual).nunique())]\n            #list(np.arange(0, actual.nunique()))\n            y = x\n        else:\n            y = axis_labels\n            x = axis_labels\n\n        fig = px.imshow(cm, \n                    text_auto=True,\n                    aspect='auto',\n                    color_continuous_scale = 'Blues',\n                    labels = dict(x = \"Predicted Labels\",\n                                  y= \"Actual Labels\"),\n                    x = x,\n                    y = y\n                    )\n        if plot:\n            fig.show()\n\n        return cm, fig\n\n    def plotly_output_hist(actual,\n                           prediction_probs,\n                           plot=False\n                          ):\n        hist_ = px.histogram(x = prediction_probs,\n                             color = actual,\n                             nbins=100,\n                             labels=dict(color='True Labels',\n                                         x = 'Prediction Probability'\n                                        )\n                            )\n        if plot:\n            hist_.show()\n\n\n        return hist_\n\n\n    def plotly_precision_recall(actual,\n                                predictions_prob,\n                                plot=False\n                               ):\n        prec, recall, threshold = precision_recall_curve(actual, predictions_prob)\n\n        trace = go.Scatter(\n                            x=recall,\n                            y=prec,\n                            mode='lines',\n                            line=dict(color=telus_purple),\n                            fill='tozeroy',\n                            name='Precision-Recall curve'\n                        )\n        layout = go.Layout(\n                            title='Precision-Recall Curve',\n                            xaxis=dict(title='Recall'),\n                            yaxis=dict(title='Precision')\n                        )\n        fig = go.Figure(data=[trace], layout=layout)\n\n        if plot:\n            fig.show()\n\n        return fig\n\n    def plotly_roc(actual,\n                    predictions_prob,\n                    plot=False\n                   ):\n        auc_score = roc_auc_score(actual, predictions_prob)\n        fpr, tpr, thresholds  = roc_curve(actual, predictions_prob)\n\n        df = pd.DataFrame({\n                            'False Positive Rate': fpr,\n                            'True Positive Rate': tpr\n                          }, \n                            index=thresholds)\n        df.index.name = \"Thresholds\"\n        df.columns.name = \"Rate\"\n        df = df.loc[df.index <= 1]\n        fig_tpr_fpr = 0\n\n        fig_tpr_fpr= px.line(\n                            df, \n                            title='TPR and FPR at every threshold',\n                        )\n\n        # ROC Curve with AUC\n        trace = go.Scatter(\n                    x=fpr,\n                    y=tpr,\n                    mode='lines',\n                    line=dict(color=telus_purple),\n                    fill='tozeroy',\n                    name='Precision-Recall curve'\n                )\n        layout = go.Layout(\n                            title=f'ROC Curve (AUC={auc_score:.4f})',\n                            xaxis=dict(title='False Positive Rate'),\n                            yaxis=dict(title='True Positive Rate')\n                        )\n        fig_roc = go.Figure(data=[trace], layout=layout)\n\n        fig_roc.add_shape(\n            type='line', line=dict(dash='dash'),\n            x0=0, x1=1, y0=0, y1=1\n        )\n        fig_roc.update_xaxes(constrain='domain')\n\n        if plot:\n            fig_tpr_fpr.show()\n            fig_roc.show()\n\n\n        return fig_tpr_fpr, fig_roc, df, auc_score\n\n    def plotly_lift_curve(actual,\n                          predictions_prob,\n                          step=0.01,\n                          plot=False\n                         ):\n        #Define an auxiliar dataframe to plot the curve\n        aux_lift = pd.DataFrame()\n        #Create a real and predicted column for our new DataFrame and assign values\n        aux_lift['real'] = actual\n        aux_lift['predicted'] = predictions_prob\n        #Order the values for the predicted probability column:\n        aux_lift.sort_values('predicted',ascending=False,inplace=True)\n\n        #Create the values that will go into the X axis of our plot\n        x_val = np.arange(step,1+step,step)\n        #Calculate the ratio of ones in our data\n        ratio_ones = aux_lift['real'].sum() / len(aux_lift)\n        #Create an empty vector with the values that will go on the Y axis our our plot\n        y_v = []\n\n        #Calculate for each x value its correspondent y value\n        for x in x_val:\n            num_data = int(np.ceil(x*len(aux_lift))) #The ceil function returns the closest integer bigger than our number \n            data_here = aux_lift.iloc[:num_data,:]   # ie. np.ceil(1.4) = 2\n            ratio_ones_here = data_here['real'].sum()/len(data_here)\n            y_v.append(ratio_ones_here / ratio_ones)\n\n\n\n        # Lift Curve \n        trace = go.Scatter(\n                    x=x_val,\n                    y=y_v,\n                    mode='lines',\n                    line=dict(color=telus_purple),\n\n                    name='Lift Curve'\n                )\n        layout = go.Layout(\n                            title=f'Lift Curve',\n                            xaxis=dict(title='Proportion of Sample'),\n                            yaxis=dict(title='Lift')\n                        )\n        fig_lift = go.Figure(data=[trace], layout=layout)\n\n        fig_lift.add_shape(\n            type='line', line=dict(dash='dash'),\n            x0=0, x1=1, y0=1, y1=1\n        )\n        fig_lift.update_xaxes(constrain='domain')\n\n        if plot:\n            fig_lift.show()\n\n        return fig_lift\n\n    def plotly_feature_importance(model,\n                                  columns,\n                                  plot=False):\n        coefficients  = pd.DataFrame(model.feature_importances_)\n        column_data   = pd.DataFrame(columns)\n        coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                                  right_index= True, how = \"left\"))\n\n        coef_sumry.columns = [\"coefficients\",\"features\"]\n        coef_sumry = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n\n        fig_feats = 0\n        trace= go.Bar(y = coef_sumry[\"features\"].head(15).iloc[::-1],\n                      x = coef_sumry[\"coefficients\"].head(15).iloc[::-1],\n                      name = \"coefficients\",\n                      marker = dict(color = coef_sumry[\"coefficients\"],\n                                    colorscale = \"Viridis\",\n                                    line = dict(width = .6,color = \"black\")\n                                   ),\n                      orientation='h'\n                     )\n        layout = go.Layout(\n                            title='Feature Importance',\n                            yaxis=dict(title='Features')\n\n                        )\n        fig_feats = go.Figure(data=[trace], layout=layout)\n\n        if plot:\n            fig_feats.update_yaxes(automargin=True)\n            fig_feats.show()\n        return coef_sumry, fig_feats\n\n    def plotly_model_report(model,\n                            actual,\n                            predicted,\n                            predictions_prob,\n                            bucket_name,\n                            show_report = True,\n                            columns=[],\n                            save_path = ''\n                           ):\n        print(model.__class__.__name__)\n\n        metrics_df, fig_metrics = ploty_model_metrics(actual, \n                                                  predicted, \n                                                  plot=False)\n        cm, fig_cm = plotly_confusion_matrix(actual, \n                                            predicted, \n                                            axis_labels='',\n                                            plot=False)\n        fig_hist = plotly_output_hist(actual, \n                                      prediction_probs=predictions_prob,\n                                      plot=False)\n        fig_pr = plotly_precision_recall(actual,\n                                    predictions_prob,\n                                    plot=False\n                                   )\n        fig_tpr_fpr, fig_roc, _, auc_score = plotly_roc(actual,\n                                    predictions_prob,\n                                    plot=False\n                                   )\n        try:\n            coefs_df, fig_feats = plotly_feature_importance(model=model, \n                                                            columns = columns,\n                                                              plot=False)\n            coefs_df=coefs_df.to_dict()\n        except:\n            coefs_df = 0\n            pass\n        fig_lift = plotly_lift_curve(actual,\n                              predictions_prob,\n                              step=0.01,\n                              plot=False\n                             )\n        # Figure out how to put this into report on Monday -> Not Urgent\n        cr=classification_report(actual,predicted, output_dict=True)\n\n        # Generate dataframe with summary of results in one row\n\n        results_cols = ['date', 'model_name', 'estimator_type', \n                        'confusion_matrix','classification_report', \n                        'auc_score', 'feature_importances']\n        results_list = [datetime.now().strftime(\"%Y-%m-%d\"), model.__class__.__name__,  model._estimator_type,\n                        cm, cr,\n                        auc_score, coefs_df\n                       ]\n\n        results_df_combined = pd.concat([pd.DataFrame([results_list], columns=results_cols),\n                                         metrics_df],\n                                       axis=1)\n\n        # Generate Plotly page report\n\n        report_fig = make_subplots(rows=4, \n                                cols=2, \n                                print_grid=False, \n                                specs=[[{}, {}], \n                                     [{}, {}],\n                                     [{}, {}],\n                                     [{}, {}],\n                                     ],\n                                subplot_titles=('Confusion Matrix',\n                                            'Model Metrics',\n                                            'Probability Output Histogram',\n                                            'Precision - Recall curve',\n                                            'TPR & FPR Vs. Threshold',\n                                            f'ROC Curve: AUC Score {np.round(auc_score, 3)}',                                        \n                                            'Feature importance',\n                                            'Lift Curve'\n                                            )\n                                )        \n\n        report_fig.append_trace(fig_cm.data[0],1,1)\n        report_fig.update_coloraxes(showscale=False)\n        report_fig.append_trace(fig_metrics.data[0],1,2)\n\n        report_fig.append_trace(fig_hist.data[0],2,1)\n        report_fig.append_trace(fig_hist.data[1],2,1)\n        report_fig.append_trace(fig_pr.data[0],2,2)\n\n        report_fig.append_trace(fig_tpr_fpr.data[0],3,1)\n        report_fig.append_trace(fig_tpr_fpr.data[1],3,1)\n        report_fig.append_trace(fig_roc.data[0],3,2)\n        try:\n            report_fig.append_trace(fig_feats.data[0],4,1)\n        except:\n            pass\n        report_fig.append_trace(fig_lift.data[0],4,2)    \n        title_str = f\"{model.__class__.__name__} : Model performance report\"\n        report_fig['layout'].update(title = f'<b>{title_str}</b><br>',\n                        autosize = True, height = 1500,width = 1200,\n                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                        margin = dict(b = 195))\n\n        report_fig[\"layout\"][\"xaxis1\"].update(dict(title = \"Predicted Labels\"))\n        report_fig[\"layout\"][\"yaxis1\"].update(dict(title = \"Actual Labels\"))\n\n        report_fig[\"layout\"][\"xaxis3\"].update(dict(title = \"Prediction Probabilities\"))\n        report_fig[\"layout\"][\"yaxis3\"].update(dict(title = \"Count\"))\n\n        report_fig[\"layout\"][\"xaxis4\"].update(dict(title = \"Recall\"))\n        report_fig[\"layout\"][\"yaxis4\"].update(dict(title = \"Precision\"))\n\n        report_fig[\"layout\"][\"xaxis5\"].update(dict(title = \"Thresholds\"))\n        report_fig[\"layout\"][\"yaxis5\"].update(dict(title = \"Rate\"))\n\n        report_fig[\"layout\"][\"xaxis6\"].update(dict(title = \"False Positive Rate\"))\n        report_fig[\"layout\"][\"yaxis6\"].update(dict(title = \"True Positive Rate\"))\n\n        report_fig[\"layout\"][\"yaxis7\"].update(dict(title = \"Features\"))\n\n        report_fig[\"layout\"][\"xaxis8\"].update(dict(title = \"Proportion of Sample\"))\n        report_fig[\"layout\"][\"yaxis8\"].update(dict(title = \"Lift\"))             \n\n        if show_report:\n            report_fig.show()       \n\n        #Save html report\n        todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n        report_fig.write_html(f\"{save_path}{model.__class__.__name__}_{todays_date}.html\")\n        bucket = storage.Client().bucket(bucket_name)\n        filename = f\"{model.__class__.__name__}_{todays_date}.html\"\n        blob = bucket.blob(f\"{save_path}{filename}\")\n        blob.upload_from_filename(f\"{save_path}{model.__class__.__name__}_{todays_date}.html\")\n        print(f\"{filename} sucessfully uploaded to GCS bucket!\")\n\n        return results_df_combined, report_fig\n\n\n    def save_reports_to_gcs(models, y_true, y_pred, y_score, file_bucket, save_path, columns, show_report=False):\n\n        # define_the_bucket\n        bucket = storage.Client().bucket(file_bucket)\n        date=datetime.now().strftime(\"%Y-%m-%d\")\n        model_test_set_reports = []\n        model_to_report_map = {}\n\n        # If single model passed through\n        if type(models) != list:\n            models = [models]\n\n        create_folder_if_not_exists(save_path)\n\n        # Add code to set model to a list if only 1 model passed\n        for i in range(len(models)):\n\n            print(models[i])\n\n            # Pass data to generate plotly_report\n            report_df,report_fig = plotly_model_report(model=models[i],\n                                            actual=y_true,\n                                            predicted=y_pred,\n                                            predictions_prob=y_score,\n                                            bucket_name  = file_bucket,\n                                            show_report = show_report,\n                                            columns = columns,\n                                            save_path = save_path\n                                           )\n\n            todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n            model_to_report_map[models[i].__class__.__name__ ]=report_fig\n\n            # report_fig.write_html(f\"{save_path}{todays_date}_{model.__class__.__name__}.html\")\n            model_test_set_reports.append(report_df)\n\n        model_test_set_reports_concat = pd.concat(model_test_set_reports)\n\n        return model_test_set_reports_concat, model_to_report_map\n\n    df_train = pd.read_csv('gs://{}/{}/{}_train.csv'.format(file_bucket, service_type, service_type), index_col=False)  \n    df_test = pd.read_csv('gs://{}/{}/{}_validation.csv'.format(file_bucket, service_type, service_type), index_col=False)\n\n    #### For wb\n    import google.oauth2.credentials\n    CREDENTIALS = google.oauth2.credentials.Credentials(token)\n\n    client = bigquery.Client(project=project_id, credentials=CREDENTIALS)\n    job_config = bigquery.QueryJobConfig()\n\n#     #### For prod \n#     client = bigquery.Client(project=project_id)\n#     job_config = bigquery.QueryJobConfig()\n\n    #set up features (list)\n    cols_1 = df_train.columns.values\n    cols_2 = df_test.columns.values\n    cols = set(cols_1).intersection(set(cols_2))\n    features = [f for f in cols if f not in ['ban', 'target', 'Unnamed: 0']]\n\n    #train test split\n    df_train, df_val = train_test_split(df_train, shuffle=True, test_size=0.25, random_state=42,\n                                        stratify=df_train['target']\n                                        )\n\n    create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    df_train.to_csv('gs://{}/{}/backup/{}_train_{}.csv'.format(file_bucket, service_type, service_type, create_time))\n    df_val.to_csv('gs://{}/{}/backup/{}_val_{}.csv'.format(file_bucket, service_type, service_type, create_time))\n    df_test.to_csv('gs://{}/{}/backup/{}_test_{}.csv'.format(file_bucket, service_type, service_type, create_time))\n\n    ban_train = df_train['ban']\n    X_train = df_train[features]\n    y_train = np.squeeze(df_train['target'].values)\n\n    ban_val = df_val['ban']\n    X_val = df_val[features]\n    y_val = np.squeeze(df_val['target'].values)\n\n    ban_test = df_test['ban']\n    X_test = df_test[features]\n    y_test = np.squeeze(df_test['target'].values)\n\n    del df_train, df_val, df_test\n    gc.collect()\n\n    # build model and fit in training data\n    # xgb_model = xgb.XGBClassifier(\n    #     learning_rate=0.1,\n    #     n_estimators=100,\n    #     max_depth=8,\n    #     min_child_weight=1,\n    #     gamma=0,\n    #     subsample=0.8,\n    #     colsample_bytree=0.8,\n    #     objective='binary:logistic',\n    #     nthread=4,\n    #     scale_pos_weight=1\n    #     # seed=27\n    # )\n\n    xgb_model = xgb.XGBClassifier(\n        learning_rate=0.02,\n        n_estimators=1000,\n        max_depth=10,\n        min_child_weight=1,\n        gamma=0,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        objective='binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        seed=27\n    )\n\n    xgb_model.fit(X_train, y_train)\n    print('xgb training done')\n\n    #predictions on X_val\n    y_pred = xgb_model.predict_proba(X_val, ntree_limit=xgb_model.best_iteration)[:, 1]\n    y_pred_label = (y_pred > 0.5).astype(int)\n    auc = roc_auc_score(y_val, y_pred_label)\n    metrics.log_metric(\"AUC\", auc)\n\n    pred_prb = xgb_model.predict_proba(X_test, ntree_limit=xgb_model.best_iteration)[:, 1]\n    lg = get_lift(pred_prb, y_test, 10)\n\n    y_true = y_test\n    y_pred = (pred_prb > 0.5).astype(int)\n    y_score = pred_prb \n\n    model_reports, model_to_report_map = save_reports_to_gcs(models = xgb_model\n                                                            , y_true = y_true\n                                                            , y_pred = y_pred \n                                                            , y_score = y_score\n                                                            , file_bucket = file_bucket\n                                                            , save_path = 'churn_12_months/reports/'\n                                                            , columns = features\n                                                            , show_report=False\n                                                            )\n\n    model_class_name = xgb_model.__class__.__name__\n    final_model_report = model_to_report_map[model_class_name]    \n\n    #### Save the Report and Model \n    storage_client = storage.Client()\n    bucket = storage_client.get_bucket(file_bucket)\n\n    # save the model in GCS\n    models_dict = {}\n    create_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    models_dict['create_time'] = create_time\n    models_dict['model'] = xgb_model\n    models_dict['features'] = features\n    lg.to_csv('gs://{}/{}/lift_on_scoring_data_{}.csv'.format(file_bucket, service_type, create_time, index=False))\n\n    with open('model_dict.pkl', 'wb') as handle:\n        pickle.dump(models_dict, handle)\n    handle.close()\n\n    MODEL_PATH = '{}/{}_xgb_models/'.format(service_type, service_type)\n    blob = bucket.blob(MODEL_PATH)\n    if not blob.exists(storage_client):\n        blob.upload_from_string('')\n\n    model_name_onbkt = '{}{}_models_xgb_{}'.format(MODEL_PATH, service_type, models_dict['create_time'])\n    blob = bucket.blob(model_name_onbkt)\n    blob.upload_from_filename('model_dict.pkl')\n\n    model.uri = f'gs://{file_bucket}/{model_name_onbkt}'\n\n    print(f\"....model loaded to GCS done at {str(create_time)}\")\n\n    col_list = features\n\n    return (col_list, model.uri)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 64.0
            }
          }
        },
        "exec-upload-model": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "upload_model"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef upload_model(\n    project_id: str,\n    model: Input[Model],\n    vertex_model: Output[Model],\n    region: str,\n    model_name: str,\n    prediction_image: str,\n    col_list: list, \n    model_uri: str\n    )-> NamedTuple(\"output\", [(\"model_uri\", str)]):\n    \"\"\"\n    Upload model to Vertex Model Registry.\n    Args:\n        project_id (str): project id for where this pipeline is being run\n        model (Input[Model]): model passed in from training component. Must have path specified in model.uri\n        region (str): region for where the query will be run\n        model_name (str): name of model to be stored\n        prediction_image (str): prediction image uri\n        col_list (str): string of list of columns in serving data\n    Returns:\n        vertex_model (Output[Model]): Model saved in Vertex AI\n    \"\"\"\n\n    from google.cloud import aiplatform\n    import os\n\n    aiplatform.init(project=project_id, location=region)\n\n    ## check if prediction image is custom or not\n    if prediction_image.startswith('northamerica-northeast1-docker'):\n        # custom: must set ports\n        health_route = \"/ping\"\n        predict_route = \"/predict\"\n        serving_container_ports = [7080]\n    else:\n        # Google pre-built\n        health_route = None\n        predict_route = None\n        serving_container_ports = None\n\n    ## check for existing models\n    # if model exists, update the version\n    try:\n        model_uid = aiplatform.Model.list(\n            filter=f'display_name={model_name}', \n            order_by=\"update_time\",\n            location=region)[-1].resource_name\n\n        uploaded_model = aiplatform.Model.upload(\n            display_name = model_name, \n            artifact_uri = os.path.dirname(model.uri),\n            serving_container_image_uri = prediction_image,\n            serving_container_predict_route=predict_route,\n            serving_container_health_route=health_route,\n            serving_container_ports=serving_container_ports,\n            serving_container_environment_variables =  {\"COL_LIST\":str(col_list), \"model_uri\": model_uri},\n            parent_model = model_uid,\n            is_default_version = True\n        )\n    # if model does not already exist, create a new model\n    except:\n        uploaded_model = aiplatform.Model.upload(\n            display_name = model_name,\n            artifact_uri = os.path.dirname(model.uri),\n            serving_container_image_uri=prediction_image,\n            serving_container_predict_route=predict_route,\n            serving_container_health_route=health_route,\n            serving_container_ports=serving_container_ports,\n            serving_container_environment_variables =  {\"COL_LIST\":str(col_list), \"model_uri\": model_uri},\n        )\n\n    vertex_model.uri = uploaded_model.resource_name\n\n    return (vertex_model.uri,)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-load-model-slim:1.0.0",
            "resources": {
              "cpuLimit": 4.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-visualize-stats": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "visualize_stats"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.18' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef visualize_stats(\n    statistics: Input[Artifact],\n    view: Output[HTML],\n    op_type: str = \"\",\n    stats_nm: str = \"\",\n    base_stats_path: str = None,\n    base_stats_nm: str = \"\"\n):\n    '''\n    Inputs:\n        - op_type: training or serving or predictions\n        - stats_nm: name of new stats\n        - base_stats_path: path to base stats in gcs (usually training)\n        - base_stats_nm: base stats name\n        - statistics: path to statistics imported from generate stats component\n\n    Outputs:\n        - html artifact\n    '''\n\n    import tensorflow_data_validation as tfdv\n    from tensorflow_data_validation.utils.display_util import (\n        get_statistics_html,\n    )\n\n    # load stats\n    stats = tfdv.load_statistics(input_path=statistics.uri)\n    print(\"statistics uri\")\n    print(statistics.uri)\n\n    # create html content\n    if base_stats_path is not None:\n        base_stats = tfdv.load_statistics(input_path=base_stats_path)\n\n        html = get_statistics_html(\n            lhs_statistics=stats,\n            lhs_name=stats_nm,\n            rhs_statistics=base_stats,\n            rhs_name=base_stats_nm,\n        )\n\n    else:\n        html = get_statistics_html(\n            lhs_statistics=stats,\n            lhs_name=stats_nm,\n        )\n\n    # ensure view is stored as html (this will set content-type to text/html)\n    if not view.path.endswith(\".html\"):\n        view.path += \".html\"\n\n    print(\"view path\")\n    print(view.path)\n\n    # write html to output file\n    with open(view.path, \"w\") as f:\n        f.write(html)\n\n"
            ],
            "image": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-tfdv-slim:1.0.0"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "churn-12-months-train-pipeline"
    },
    "root": {
      "dag": {
        "outputs": {
          "artifacts": {
            "train-and-save-model-metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metrics",
                  "producerSubtask": "train-and-save-model"
                }
              ]
            },
            "train-and-save-model-metricsc": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "metricsc",
                  "producerSubtask": "train-and-save-model"
                }
              ]
            }
          }
        },
        "tasks": {
          "bq-create-dataset": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-create-dataset"
            },
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "environment": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "training"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "region": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "northamerica-northeast1"
                    }
                  }
                },
                "score_date": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "2022-09-01"
                    }
                  }
                },
                "score_date_delta": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "0"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0AfB_byDszYwLQM8fZyWKanEozBejvGwmIvQDkXozwHvoP48PAwEMI0EObT8ey_5uF-_SJB2xAgZNe7RQb5gmA2VpIsh3k0Ga2pocG85-k1Ta1Rl0sRldfA0tcvz4X9qu7kMYnz1gUyS10jIRLS9jte-9Fi1opFE6bxoXY_zRZHDeaCgYKARUSARISFQGOcNnCtZHQWomO4JbKk__R4cjMBg0179"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-create-dataset"
            }
          },
          "bq-create-dataset-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-bq-create-dataset-2"
            },
            "dependentTasks": [
              "preprocess"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "environment": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "validation"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "region": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "northamerica-northeast1"
                    }
                  }
                },
                "score_date": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "2022-09-01"
                    }
                  }
                },
                "score_date_delta": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "0"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0AfB_byDszYwLQM8fZyWKanEozBejvGwmIvQDkXozwHvoP48PAwEMI0EObT8ey_5uF-_SJB2xAgZNe7RQb5gmA2VpIsh3k0Ga2pocG85-k1Ta1Rl0sRldfA0tcvz4X9qu7kMYnz1gUyS10jIRLS9jte-9Fi1opFE6bxoXY_zRZHDeaCgYKARUSARISFQGOcNnCtZHQWomO4JbKk__R4cjMBg0179"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "bq-create-dataset-2"
            }
          },
          "generate-data-stats": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-generate-data-stats"
            },
            "dependentTasks": [
              "preprocess-2"
            ],
            "inputs": {
              "parameters": {
                "bucket_nm": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a-default"
                    }
                  }
                },
                "data_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "csv"
                    }
                  }
                },
                "date_col": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "date_filter": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "dest_schema_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-josh-pr-d1cc3a-default/churn_12_months/schemas/training_stats_schema_2023-10-20"
                    }
                  }
                },
                "dest_stats_bq_dataset": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "dest_stats_gcs_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-josh-pr-d1cc3a-default/churn_12_months/statistics/training_statistics_2023-10-20"
                    }
                  }
                },
                "in_bq_ind": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "1"
                    }
                  }
                },
                "model_nm": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "model_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "supervised"
                    }
                  }
                },
                "op_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "training"
                    }
                  }
                },
                "pass_through_features": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "[\"ban\"]"
                    }
                  }
                },
                "pred_cols": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "[]"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "row_sample": {
                  "runtimeValue": {
                    "constantValue": {
                      "doubleValue": 1.0
                    }
                  }
                },
                "src_bq_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "src_csv_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-josh-pr-d1cc3a-default/churn_12_months/churn_12_months_train.csv"
                    }
                  }
                },
                "table_block_sample": {
                  "runtimeValue": {
                    "constantValue": {
                      "doubleValue": 1.0
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0AfB_byDszYwLQM8fZyWKanEozBejvGwmIvQDkXozwHvoP48PAwEMI0EObT8ey_5uF-_SJB2xAgZNe7RQb5gmA2VpIsh3k0Ga2pocG85-k1Ta1Rl0sRldfA0tcvz4X9qu7kMYnz1gUyS10jIRLS9jte-9Fi1opFE6bxoXY_zRZHDeaCgYKARUSARISFQGOcNnCtZHQWomO4JbKk__R4cjMBg0179"
                    }
                  }
                },
                "training_target_col": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "target"
                    }
                  }
                },
                "update_ts": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "2023-10-20 02:41:08"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "generate-training-data-statistics"
            }
          },
          "preprocess": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-preprocess"
            },
            "dependentTasks": [
              "bq-create-dataset"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "pipeline_dataset": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bq_c12m_training_dataset"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-josh-pr-d1cc3a-default/churn_12_months/churn_12_months_train.csv"
                    }
                  }
                },
                "score_date_dash": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "2022-09-01"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "preprocess"
            }
          },
          "preprocess-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-preprocess-2"
            },
            "dependentTasks": [
              "bq-create-dataset-2"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "pipeline_dataset": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "bq_c12m_validation_dataset"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "save_data_path": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "gs://divg-josh-pr-d1cc3a-default/churn_12_months/churn_12_months_validation.csv"
                    }
                  }
                },
                "score_date_dash": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "2022-09-01"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "preprocess-2"
            }
          },
          "train-and-save-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-train-and-save-model"
            },
            "dependentTasks": [
              "preprocess-2"
            ],
            "inputs": {
              "parameters": {
                "dataset_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "file_bucket": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a-default"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "service_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "token": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "ya29.a0AfB_byDszYwLQM8fZyWKanEozBejvGwmIvQDkXozwHvoP48PAwEMI0EObT8ey_5uF-_SJB2xAgZNe7RQb5gmA2VpIsh3k0Ga2pocG85-k1Ta1Rl0sRldfA0tcvz4X9qu7kMYnz1gUyS10jIRLS9jte-9Fi1opFE6bxoXY_zRZHDeaCgYKARUSARISFQGOcNnCtZHQWomO4JbKk__R4cjMBg0179"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "train-and-save-model"
            }
          },
          "upload-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-upload-model"
            },
            "dependentTasks": [
              "train-and-save-model"
            ],
            "inputs": {
              "artifacts": {
                "model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "model",
                    "producerTask": "train-and-save-model"
                  }
                }
              },
              "parameters": {
                "col_list": {
                  "taskOutputParameter": {
                    "outputParameterKey": "col_list",
                    "producerTask": "train-and-save-model"
                  }
                },
                "model_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "churn_12_months"
                    }
                  }
                },
                "model_uri": {
                  "taskOutputParameter": {
                    "outputParameterKey": "model_uri",
                    "producerTask": "train-and-save-model"
                  }
                },
                "prediction_image": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "northamerica-northeast1-docker.pkg.dev/cio-workbench-image-np-0ddefe/bi-platform/bi-aaaie/images/kfp-pycaret-slim:latest"
                    }
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "divg-josh-pr-d1cc3a"
                    }
                  }
                },
                "region": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "northamerica-northeast1"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "upload-model"
            }
          },
          "visualize-stats": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-visualize-stats"
            },
            "dependentTasks": [
              "generate-data-stats"
            ],
            "inputs": {
              "artifacts": {
                "statistics": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "statistics",
                    "producerTask": "generate-data-stats"
                  }
                }
              },
              "parameters": {
                "base_stats_nm": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": ""
                    }
                  }
                },
                "op_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "training"
                    }
                  }
                },
                "stats_nm": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "Training Data Statistics 2023-10-20 02:41:08"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "visualize-Training-data-statistics"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "file_bucket": {
            "type": "STRING"
          },
          "project_id": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          },
          "resource_bucket": {
            "type": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "train-and-save-model-metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "train-and-save-model-metricsc": {
            "artifactType": {
              "schemaTitle": "system.ClassificationMetrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.18"
  },
  "runtimeConfig": {
    "parameters": {
      "file_bucket": {
        "stringValue": "divg-josh-pr-d1cc3a-default"
      },
      "project_id": {
        "stringValue": "divg-josh-pr-d1cc3a"
      },
      "region": {
        "stringValue": "northamerica-northeast1"
      },
      "resource_bucket": {
        "stringValue": "divg-josh-pr-d1cc3a-default"
      }
    }
  }
}