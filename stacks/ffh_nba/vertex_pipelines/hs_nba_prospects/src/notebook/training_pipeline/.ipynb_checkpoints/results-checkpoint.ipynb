{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d20f22-15fc-41d5-a0d9-3fe012d3d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import global modules\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from yaml import safe_load\n",
    "\n",
    "# Set global vars\n",
    "pth_project = Path(os.getcwd().split('notebooks')[0])\n",
    "pth_data = pth_project / 'data'\n",
    "pth_utils = pth_project / 'utils'\n",
    "pth_queries = pth_project / 'queries'\n",
    "pth_creds = pth_project / 'conf' / 'local' / 'project_config.yaml'\n",
    "sys.path.insert(0, pth_project.as_posix())\n",
    "d_config = safe_load(pth_creds.open())\n",
    "\n",
    "# import local modules\n",
    "from utils.gcp import connect_bq_services\n",
    "from utils.etl.extract import extract_bq_data\n",
    "from utils.modeling import process_features, extract_stats\n",
    "from utils.naive_models import naive_model_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80312ba2-0be7-4c47-9bd1-b83198ddacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = connect_bq_services(d_config['gcp-project-name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6aeaa9-05fc-48f2-af11-ac0ccc813988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14550ea5-3ed7-4fe9-a45e-cd7fc6ae7057",
   "metadata": {},
   "source": [
    "#### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cca01f-6fc0-44bf-98c8-cce647e68bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = (pth_queries / 'extract_aia_predictions.sql').read_text()\n",
    "df_results = extract_bq_data(bq_client, sql)\n",
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf73858-1c35-4f51-b0fa-16beae0d6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_target_mapping = {\n",
    " 'sing_acquisition': 0,\n",
    " 'shs_acquisition': 1,\n",
    " 'tos_acquisition': 2,\n",
    " 'wifi_acquisition': 3,\n",
    " 'ttv_acquisition': 4,\n",
    " 'sws_acquisition': 5,\n",
    " 'hsic_acquisition': 6,\n",
    " 'lwc_acquisition': 7,\n",
    " 'hpro_acquisition': 8,\n",
    " 'whsia_acquisition': 9,\n",
    "}\n",
    "\n",
    "d_target_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a1cb6-4311-4808-8d32-b924641c0d18",
   "metadata": {},
   "source": [
    "#### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd929c39-a47a-4398-9692-8276a3f542df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted columns\n",
    "l_pred_cols = [c for c in df_results.columns if '_predicted_score_calibrated' in c]\n",
    "len(l_pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd83534-16f5-4730-b0ec-95d152fb4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label columns\n",
    "l_label_cols = [c for c in df_results.columns if '_label' in c]\n",
    "len(l_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb1e35-dd10-4d55-be00-dd327ce5628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[l_label_cols].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcee3a1-b9ab-40c3-9332-3bd6b97b9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[['ban', 'cust_id', 'lpds_id']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f441e67-500f-4838-8f37-a41c34205483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate labels\n",
    "df_results['model_scenario'] = df_results.apply(\n",
    "    lambda row: [\n",
    "        label.replace('_label', '_acquisition') for label in l_label_cols \n",
    "        if pd.notnull(row[label]) and row[label] == 1\n",
    "    ], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ef4df-d92f-40af-bbcc-d6fb3cfff031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[['model_scenario'] + l_label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5cf5c1-c656-4c83-83b6-a5883cedd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode labels\n",
    "df_res_exploded = df_results.explode('model_scenario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c954409-eee6-4af8-9ed8-b5cc6acda459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_exploded[['ban', 'model_scenario'] + l_label_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e73f9-e5a5-4783-8cc9-ac6f03e1e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_exploded['model_scenario'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d759e-5441-479d-9559-995222301ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target indexes\n",
    "df_res_exploded['target'] = df_res_exploded['model_scenario'].map(d_target_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f4dc5-4598-4536-a479-81128dc6709e",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3a49a-78ce-4ad3-bdc4-dd3fb20edb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creta list with same order of label indexes\n",
    "l_pred_ordered = [label.replace('_acquisition', '_predicted_score_calibrated') for label in d_target_mapping.keys()]\n",
    "len(l_pred_ordered), set(l_pred_ordered) == set(l_pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6781ffd-bf05-4748-9983-ec9a39f5f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities =  df_res_exploded[l_pred_ordered].to_numpy()\n",
    "results_ranked = np.argsort(-probabilities, axis=1)\n",
    "display(extract_stats(3, results_ranked, df_res_exploded['target'], d_target_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cee7d-d779-4cf1-af5f-29bc4ccd436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import global modules\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from pathlib import Path\n",
    "from yaml import safe_load\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pth = Path(os.getcwd()) \n",
    "\n",
    "pth_model_config = pth / 'model_config.yaml'\n",
    "model_type = 'acquisition'\n",
    "\n",
    "d_model_config = safe_load(pth_model_config.open())\n",
    "\n",
    "# extract target name - index mapping\n",
    "d_target_mapping = {\n",
    "    d_target_info['class_index']: d_target_info['name'] \n",
    "    for d_target_info in d_model_config['target_variables'][model_type]\n",
    "}\n",
    "\n",
    "print(d_target_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b70ffd-2b5f-4ac2-a36a-a95150dad591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import global modules\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "def evaluate(df_result: pd.DataFrame, \n",
    "             file_bucket: str, \n",
    "             service_type: str, \n",
    "             model_type: str, \n",
    "             d_model_config: dict, \n",
    "             stats_file_name: str\n",
    "             ):\n",
    "    \"\"\"\n",
    "    This function evaluates the prospects NBA model based on the predictions it made on validation set. It takes the following parameters:\n",
    "    \n",
    "    Args:\n",
    "        - df_result: Returned dataset from train() function\n",
    "        - file_bucket: A GCS Bucket where training dataset is saved.\n",
    "        - service_type: Service type name\n",
    "        - model_type: 'acquisition' or 'tier'\n",
    "        - d_model_config: A dictionary containing the metadata information for the model.\n",
    "        - stats_file_name: The name of the file that contains df_stats. \n",
    "\n",
    "    Returns:\n",
    "        - pd.DataFrame: The processed dataframe with additional features and mapped target values.\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_stats(\n",
    "        file_bucket: str, \n",
    "        service_type: str, \n",
    "        stats_file_name: str, \n",
    "        n: int, \n",
    "        predictions_ranked: np.array, \n",
    "        true_values: np.array,\n",
    "        d_target_mapping: dict\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Extracts statistics and metrics for evaluating predictions ranked by their probability scores.\n",
    "\n",
    "        Parameters:\n",
    "        n (int): The number of predictions to consider in the top N.\n",
    "        predictions_ranked (np.array): An array of ranked predictions.\n",
    "        true_values (np.array): An array of true values corresponding to the predictions.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing statistics and metrics for evaluating the predictions.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # true_predctions - check if prediction is in top n\n",
    "        l_results = [\n",
    "            1 if true_value in prediction[:n] else 0\n",
    "            for prediction, true_value in zip(predictions_ranked, true_values)\n",
    "        ]\n",
    "\n",
    "        # build results dataframe\n",
    "        df_results = pd.DataFrame(true_values)\n",
    "        df_results = df_results.rename(columns = {df_results.columns[0]: 'label'})\n",
    "        df_results[f'is_prediction_in_top_{n}'] = l_results\n",
    "\n",
    "        # aggregate by label\n",
    "        df_stats = df_results.groupby('label').agg({\n",
    "            'label': 'count',\n",
    "            f'is_prediction_in_top_{n}': 'sum'\n",
    "        }).rename(\n",
    "            columns = {\n",
    "                'label': 'n_acquisitions'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # capture rate\n",
    "        capture_rate = df_stats[f'is_prediction_in_top_{n}'] / df_stats['n_acquisitions']\n",
    "        df_stats[f'capture_rate_top_{n}'] = round(capture_rate * 100, 2)\n",
    "\n",
    "        # add product names\n",
    "        df_stats['product'] = ''\n",
    "        for name, idx in d_target_mapping.items():\n",
    "            df_stats.at[idx, 'product'] = name\n",
    "\n",
    "        # calculate the weighted average and append to df\n",
    "        w_avg = (df_stats[f'capture_rate_top_{n}'] * df_stats['n_acquisitions']).sum() / df_stats['n_acquisitions'].sum()\n",
    "        total_correct_predictions = df_stats[f'is_prediction_in_top_{n}'].sum()\n",
    "        df_w_avg = pd.DataFrame({\n",
    "            'n_acquisitions': [df_stats['n_acquisitions'].sum()],\n",
    "            f'is_prediction_in_top_{n}': [total_correct_predictions],\n",
    "            f'capture_rate_top_{n}': [round(w_avg, 2)],\n",
    "            'product': [f'weighted_avg']    \n",
    "        })\n",
    "        df_stats = pd.concat([df_stats, df_w_avg])\n",
    "\n",
    "        df_stats.to_csv(f'gs://{file_bucket}/{service_type}/{stats_file_name}', index=False)\n",
    "        \n",
    "        return df_stats\n",
    "\n",
    "    df_result = pd.read_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_product_reco_prospects/training_dataset.csv', index_col=None)\n",
    "\n",
    "    # extract target name - index mapping\n",
    "    d_target_mapping = {\n",
    "        d_target_info['name']: d_target_info['class_index']\n",
    "        for d_target_info in d_model_config['target_variables'][model_type]\n",
    "    }\n",
    "\n",
    "    # creta list with same order of label indexes\n",
    "    l_pred_ordered = [label for label in d_target_mapping.keys()]\n",
    "    l_pred_ordered = ['y_pred_0', 'y_pred_1', 'y_pred_2', 'y_pred_3', 'y_pred_4', 'y_pred_5', 'y_pred_6', 'y_pred_7', 'y_pred_8', 'y_pred_9']\n",
    "    probabilities =  df_result[l_pred_ordered].to_numpy()\n",
    "    results_ranked = np.argsort(-probabilities, axis=1)\n",
    "    display(extract_stats(3, results_ranked, df_res_exploded['target'], d_target_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03437eda-4136-4714-98ac-fbc4af1c5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import global modules\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from pathlib import Path\n",
    "from yaml import safe_load\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pth = Path(os.getcwd()) \n",
    "\n",
    "pth_model_config = pth / 'model_config.yaml'\n",
    "\n",
    "d_model_config = safe_load(pth_model_config.open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab35a7f-6e1e-4796-951c-56e4e9bc6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_stats(\n",
    "    n: int, \n",
    "    predictions_ranked: np.array, \n",
    "    true_values: np.array,\n",
    "    d_target_mapping: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts statistics and metrics for evaluating predictions ranked by their probability scores.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): The number of predictions to consider in the top N.\n",
    "    predictions_ranked (np.array): An array of ranked predictions.\n",
    "    true_values (np.array): An array of true values corresponding to the predictions.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing statistics and metrics for evaluating the predictions.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # true_predctions - check if prediction is in top n\n",
    "    l_results = [\n",
    "        1 if true_value in prediction[:n] else 0\n",
    "        for prediction, true_value in zip(predictions_ranked, true_values)\n",
    "    ]\n",
    "\n",
    "    # build results dataframe\n",
    "    df_results = pd.DataFrame(true_values)\n",
    "    df_results = df_results.rename(columns = {df_results.columns[0]: 'label'})\n",
    "    df_results[f'is_prediction_in_top_{n}'] = l_results\n",
    "\n",
    "    # aggregate by label\n",
    "    df_stats = df_results.groupby('label').agg({\n",
    "        'label': 'count',\n",
    "        f'is_prediction_in_top_{n}': 'sum'\n",
    "    }).rename(\n",
    "        columns = {\n",
    "            'label': 'n_acquisitions'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # capture rate\n",
    "    capture_rate = df_stats[f'is_prediction_in_top_{n}'] / df_stats['n_acquisitions']\n",
    "    df_stats[f'capture_rate_top_{n}'] = round(capture_rate * 100, 2)\n",
    "\n",
    "    # add product names\n",
    "    df_stats['product'] = ''\n",
    "    for name, idx in d_target_mapping.items():\n",
    "        df_stats.at[idx, 'product'] = name\n",
    "\n",
    "    # calculate the weighted average and append to df\n",
    "    w_avg = (df_stats[f'capture_rate_top_{n}'] * df_stats['n_acquisitions']).sum() / df_stats['n_acquisitions'].sum()\n",
    "    total_correct_predictions = df_stats[f'is_prediction_in_top_{n}'].sum()\n",
    "    df_w_avg = pd.DataFrame({\n",
    "        'n_acquisitions': [df_stats['n_acquisitions'].sum()],\n",
    "        f'is_prediction_in_top_{n}': [total_correct_predictions],\n",
    "        f'capture_rate_top_{n}': [round(w_avg, 2)],\n",
    "        'product': [f'weighted_avg']    \n",
    "    })\n",
    "    df_stats = pd.concat([df_stats, df_w_avg])\n",
    "    \n",
    "    df_stats.to_csv(f'gs://{file_bucket}/{service_type}/{stats_file_name}', index=False)\n",
    "    \n",
    "    return df_stats\n",
    "\n",
    "df_result = pd.read_csv('gs://divg-groovyhoon-pr-d2eab4-default/nba_product_reco_prospects/df_val_exp.csv', index_col=None)\n",
    "\n",
    "target = d_model_config['target']\n",
    "\n",
    "# extract target name - index mapping\n",
    "d_target_mapping = {\n",
    "    d_target_info['name']: d_target_info['class_index']\n",
    "    for d_target_info in d_model_config['target_variables'][model_type]\n",
    "}\n",
    "\n",
    "# creta list with same order of label indexes\n",
    "l_pred_ordered = [label for label in d_target_mapping.keys()]\n",
    "probabilities =  df_result[l_pred_ordered].to_numpy()\n",
    "results_ranked = np.argsort(-probabilities, axis=1)\n",
    "# display(extract_stats(3, results_ranked, df_result[target], d_target_mapping))\n",
    "display(extract_stats(3, results_ranked, df_result['y_val'], d_target_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74aea1c-2f45-43dc-9fec-7ec9a6f11cf7",
   "metadata": {},
   "source": [
    "#### ADnA approche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa179f64-c951-46dd-89c8-93fe6db15177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract trainning data\n",
    "sql = f\"\"\"\n",
    "select *\n",
    "  from `wb-nba-1-pr-08a45b.features_v4.master_features_set_20240213_existing_and_new`\n",
    "  where split_type = '1-train'\n",
    "    and label = 1 and label_desc= 'acquisition'\n",
    "\"\"\"\n",
    "df_train = extract_bq_data(bq_client, sql)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aba53a-6049-48d8-9a1d-02f7c86e1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features metadata\n",
    "d_features_metadata = safe_load((pth_utils / 'parameters' / 'acquisition_features_v9.yaml').open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5fd79-e1b1-425b-b2a2-a432cbe5e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process training data\n",
    "df_train_processed = process_features(df_train, d_features_metadata, 'model_scenario', d_target_mapping)\n",
    "df_res_exploded_processed = process_features(df_res_exploded, d_features_metadata, 'model_scenario', d_target_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61f311-439d-499a-9453-066029633e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_processed.drop(columns='target')\n",
    "y_train = df_train_processed['target']\n",
    "\n",
    "X_val = df_res_exploded_processed.drop(columns='target')\n",
    "y_val = df_res_exploded_processed['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9afee-3d7d-480e-a1c5-f23d814e644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941776e-4210-4aea-8a12-2d45106d47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "probabilities =  xgb_model.predict_proba(X_val)\n",
    "results_ranked = np.argsort(-probabilities, axis=1)\n",
    "display(extract_stats(n, results_ranked, y_val, d_target_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4422b-e046-4728-a18f-67683a25d0c8",
   "metadata": {},
   "source": [
    "#### Naive approche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d36e9-f767-4f4d-85af-c951a28327ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290dfa3-275f-4fbc-b2e9-96a5fdc14302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type in ('volume_only', 'random_only', 'random_weighted'):\n",
    "    print(model_type)\n",
    "    \n",
    "    probabilities = naive_model_predict_proba(\n",
    "        df_res_exploded, 'target', d_target_mapping, score_type = model_type,\n",
    "        eligible_rule = False, existing_prod_rule = False,\n",
    "    )\n",
    "    results_ranked = np.argsort(-probabilities, axis=1)\n",
    "    display(extract_stats(n, results_ranked, df_res_exploded['target'], d_target_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ced16-abeb-4432-9bdc-d3a842f48e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'color': ['red', 'green', 'blue', 'green', 'red', 'blue']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'color' column\n",
    "df['color'] = le.fit_transform(df['color'])\n",
    "\n",
    "print(\"\\nDataFrame after Label Encoding:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24bcc6-beb4-4aa5-9b4e-676dd80019d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eee68a-c570-44c0-9498-9554ff1b44f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
